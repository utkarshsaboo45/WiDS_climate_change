{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff3a1ff-064c-4305-8703-6ee797f36315",
   "metadata": {},
   "source": [
    "# WiDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f72f47-6aa3-4f15-85d2-07554b71c8d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925f3d9-4a25-4d90-b850-2acdefc24feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa526a-1934-4496-af84-57fd47588b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/train.csv\")\n",
    "# # df.drop(columns=[\"id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a165e-0957-436a-ba0f-7eeb7144fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET_COLUMN = \"site_eui\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6cd4a-b254-4342-b592-6474d8837e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_data = df.select_dtypes(include=[np.number])\n",
    "# categorical_data = df.select_dtypes(exclude=[np.number])\n",
    "\n",
    "# numeric_features = numeric_data.columns.tolist()\n",
    "# numeric_features.remove(TARGET_COLUMN)\n",
    "# categorical_features = categorical_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ca70c-d1e8-43f9-bff5-aab3eb9496e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5ef15-47a7-45a2-8fb7-7a9b5e1db783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792db92d-e8df-416e-8bbb-67b5ac869b35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Feature Engineering/Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea739c9-d792-43e9-9910-1f2c375b2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Standard Deviation of min, max and avg temp among months\n",
    "min_temps = [\n",
    "    \"january_min_temp\",\n",
    "    \"february_min_temp\",\n",
    "    \"march_min_temp\",\n",
    "    \"april_min_temp\",\n",
    "    \"may_min_temp\",\n",
    "    \"june_min_temp\",\n",
    "    \"july_min_temp\",\n",
    "    \"august_min_temp\",\n",
    "    \"september_min_temp\",\n",
    "    \"october_min_temp\",\n",
    "    \"november_min_temp\",\n",
    "    \"december_min_temp\"\n",
    "]\n",
    "\n",
    "max_temps = [\n",
    "    \"january_max_temp\",\n",
    "    \"february_max_temp\",\n",
    "    \"march_max_temp\",\n",
    "    \"april_max_temp\",\n",
    "    \"may_max_temp\",\n",
    "    \"june_max_temp\",\n",
    "    \"july_max_temp\",\n",
    "    \"august_max_temp\",\n",
    "    \"september_max_temp\",\n",
    "    \"october_max_temp\",\n",
    "    \"november_max_temp\",\n",
    "    \"december_max_temp\"\n",
    "]\n",
    "\n",
    "avg_temps = [\n",
    "    \"january_avg_temp\",\n",
    "    \"february_avg_temp\",\n",
    "    \"march_avg_temp\",\n",
    "    \"april_avg_temp\",\n",
    "    \"may_avg_temp\",\n",
    "    \"june_avg_temp\",\n",
    "    \"july_avg_temp\",\n",
    "    \"august_avg_temp\",\n",
    "    \"september_avg_temp\",\n",
    "    \"october_avg_temp\",\n",
    "    \"november_avg_temp\",\n",
    "    \"december_avg_temp\",\n",
    "]\n",
    "\n",
    "df[\"min_temp_std\"] = df[min_temps].T.std()\n",
    "df[\"max_temp_std\"] = df[max_temps].T.std()\n",
    "df[\"avg_temp_std\"] = df[avg_temps].T.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6059b79-8be8-4056-aa64-f833bdbde904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2a894-b6ce-4849-9149-0fd764b66349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find monthwise difference between the temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72dd7b-3c90-4239-89a9-5036d250e2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3b73f-2152-4af9-965f-41502a1375fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_above ranges\n",
    "# days_below ranges\n",
    "# find their sums to see if they are yearly/monthly/etc.\n",
    "days_above_below = [\n",
    "    \"days_below_30F\",\n",
    "    \"days_below_20F\",\n",
    "    \"days_below_10F\",\n",
    "    \"days_below_0F\",\n",
    "    \"days_above_80F\",\n",
    "    \"days_above_90F\",\n",
    "    \"days_above_100F\",\n",
    "    \"days_above_110F\",\n",
    "]\n",
    "\n",
    "df[\"0-10\"] = df[\"days_below_10F\"] - df[\"days_below_0F\"]\n",
    "df[\"10-20\"] = df[\"days_below_20F\"] - df[\"days_below_10F\"]\n",
    "df[\"20-30\"] = df[\"days_below_30F\"] - df[\"days_below_20F\"]\n",
    "df[\"80-90\"] = df[\"days_above_80F\"] - df[\"days_above_90F\"]\n",
    "df[\"90-100\"] = df[\"days_above_90F\"] - df[\"days_above_100F\"]\n",
    "df[\"100-110\"] = df[\"days_above_100F\"] - df[\"days_above_110F\"]\n",
    "df[\"30-80\"] = (366 - df[days_above_below].sum(axis=1)).clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83979a3-ef67-4a3f-a658-d2abe24e44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do something about missing values in direction_max_wind_speed and direction_peak_wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70608db5-e337-417f-a638-f7b38f24eeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71904f-b693-4478-b51d-eba241e57207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"floor_area\",\n",
    "    \"year_built\",\n",
    "    \"energy_star_rating\",\n",
    "    \"ELEVATION\",\n",
    "    \n",
    "    # \"january_min_temp\",\n",
    "    # \"january_avg_temp\",\n",
    "    # \"january_max_temp\",\n",
    "    # \"february_min_temp\",\n",
    "    # \"february_avg_temp\",\n",
    "    # \"february_max_temp\",\n",
    "    # \"march_min_temp\",\n",
    "    # \"march_avg_temp\",\n",
    "    # \"march_max_temp\",\n",
    "    # \"april_min_temp\",\n",
    "    # \"april_avg_temp\",\n",
    "    # \"april_max_temp\",\n",
    "    # \"may_min_temp\",\n",
    "    # \"may_avg_temp\",\n",
    "    # \"may_max_temp\",\n",
    "    # \"june_min_temp\",\n",
    "    # \"june_avg_temp\",\n",
    "    # \"june_max_temp\",\n",
    "    # \"july_min_temp\",\n",
    "    # \"july_avg_temp\",\n",
    "    # \"july_max_temp\",\n",
    "    # \"august_min_temp\",\n",
    "    # \"august_avg_temp\",\n",
    "    # \"august_max_temp\",\n",
    "    # \"september_min_temp\",\n",
    "    # \"september_avg_temp\",\n",
    "    # \"september_max_temp\",\n",
    "    # \"october_min_temp\",\n",
    "    # \"october_avg_temp\",\n",
    "    # \"october_max_temp\",\n",
    "    # \"november_min_temp\",\n",
    "    # \"november_avg_temp\",\n",
    "    # \"november_max_temp\",\n",
    "    # \"december_min_temp\",\n",
    "    # \"december_avg_temp\",\n",
    "    # \"december_max_temp\",\n",
    "    \n",
    "    \"cooling_degree_days\",\n",
    "    \"heating_degree_days\",\n",
    "    \"precipitation_inches\",\n",
    "    \"snowfall_inches\",\n",
    "    \"snowdepth_inches\",\n",
    "    \"avg_temp\",\n",
    "    \"days_below_30F\",\n",
    "    \"days_below_20F\",\n",
    "    \"days_below_10F\",\n",
    "    \"days_below_0F\",\n",
    "    \"days_above_80F\",\n",
    "    \"days_above_90F\",\n",
    "    \"days_above_100F\",\n",
    "    \"days_above_110F\",\n",
    "    \"max_wind_speed\",\n",
    "    \"days_with_fog\",\n",
    "    \"min_temp_std\",\n",
    "    \"max_temp_std\",\n",
    "    \"avg_temp_std\",\n",
    "    \"0-10\",\n",
    "    \"10-20\",\n",
    "    \"20-30\",\n",
    "    \"30-80\",\n",
    "    \"80-90\",\n",
    "    \"90-100\",\n",
    "    \"100-110\"\n",
    "] + min_temps + max_temps + avg_temps\n",
    "\n",
    "categorical_features = [\n",
    "    \"Year_Factor\",\n",
    "    \"State_Factor\",\n",
    "    \"building_class\",\n",
    "    \"facility_type\",\n",
    "    \"direction_max_wind_speed\",\n",
    "    \"direction_peak_wind_speed\"\n",
    "]\n",
    "\n",
    "drop_columns = [\n",
    "    \"id\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd03c84-4e0f-4cf0-9649-a626eb23d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numeric_features) + len(categorical_features) + len(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e82fb-3482-4ec0-ab96-585b4d1697ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 58\n",
    "# print(numeric_features[ind])\n",
    "# print(X_train[numeric_features[ind]].value_counts().size)\n",
    "# print()\n",
    "# print(X_train[numeric_features[ind]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85939c01-a77c-4376-8b91-01443f4397f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef72f4fb-b9f2-4aa9-92d1-e9da0cbc696f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366b01f-64c6-4fcd-b229-bf4c71feb3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    FunctionTransformer,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from lightgbm.sklearn import LGBMRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd4b7b-b11b-4195-850a-af89b8bcd6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417498a-8508-44bf-b863-29c12cae718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[TARGET_COLUMN]), train_df[TARGET_COLUMN]\n",
    "X_val, y_val = val_df.drop(columns=[TARGET_COLUMN]), val_df[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72e40b-24ad-4ae1-b05b-c7970a5a9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in [X_train, X_val, y_train, y_val]:\n",
    "    print(dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914bd0c-3bd1-4c5b-a15c-101118d6f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_scores(model, X_train, y_train, X_val, y_val, return_train_score=False):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    score_dict = {\n",
    "        \"r2_val\": model.score(X_val, y_val),\n",
    "        \"mse_val\": mean_squared_error(y_val, y_val_pred),\n",
    "        \"mape_val\": mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "    }\n",
    "\n",
    "    if return_train_score:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        score_dict[\"r2_train\"] = model.score(X_train, y_train)\n",
    "        score_dict[\"mse_train\"] = mean_squared_error(y_train, y_train_pred)\n",
    "        score_dict[\"mape_train\"] = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "\n",
    "    scores_result = pd.Series(score_dict)\n",
    "\n",
    "    return model, scores_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683e880-09ef-4a78-93ce-c43ecda8466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import IterativeImputer\n",
    "mice_imp = IterativeImputer()\n",
    "# X_train_mice = X_train_numeric.copy()\n",
    "# X_val_mice = X_val_numeric.copy()\n",
    "# X_train_mice.iloc[:, :] = mice_imp.fit_transform(X_train_mice)\n",
    "# X_val_mice.iloc[:, :] = mice_imp.transform(X_val_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87522d77-b1a0-471c-8c84-8a586a9165f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyimpute import KNN\n",
    "\n",
    "knn = KNN(2)\n",
    "# X_train_categorical = X_train_categorical.copy()\n",
    "# X_val_categorical = X_val_categorical.copy()\n",
    "# X_train_categorical.iloc[:, :] = knn.fit_transform(X_train_categorical)\n",
    "# X_val_categorical.iloc[:, :] = knn.transform(X_val_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf5db1-4b65-4c98-8e87-cdba0d5f4914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd95a60-9c4d-4463-8667-463624eb2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_numeric_feats = make_pipeline(\n",
    "    mice_imp,\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "pipe_cat_feats = make_pipeline(\n",
    "    knn,\n",
    "    OneHotEncoder()\n",
    ")\n",
    "\n",
    "column_transformer = make_column_transformer(\n",
    "    (pipe_numeric_feats, numeric_features),\n",
    "    (OneHotEncoder(), categorical_features),\n",
    "    (\"drop\", drop_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1bbec-e2f7-4029-80fa-f4f7cb1d70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_transformed = column_transformer.fit_transform(X_train)\n",
    "# X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2d614-9e3c-407b-847f-888921fdda46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(column_transformer, Ridge(max_iter=10000))\n",
    "pipe_dt = make_pipeline(column_transformer, DecisionTreeRegressor())\n",
    "# pipe_svc = make_pipeline(column_transformer, SVC())\n",
    "pipe_rf = make_pipeline(column_transformer, RandomForestRegressor())\n",
    "pipe_xgb = make_pipeline(column_transformer, XGBRegressor(verbosity=0))\n",
    "pipe_lgbm = make_pipeline(column_transformer, LGBMRegressor())\n",
    "pipe_catboost = make_pipeline(column_transformer, CatBoostRegressor(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa78b2-acb3-44fd-8a19-299c14b7a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": pipe_lr,\n",
    "    \"Decision Tree\": pipe_dt,\n",
    "    \"Random Forest\": pipe_rf,\n",
    "    \"XGB\": pipe_xgb,\n",
    "    \"LGBM\": pipe_lgbm,\n",
    "    \"Cat Boost\": pipe_catboost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb9680-020e-4061-8a09-e91284d13d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     print(f\"Start {name}!\")\n",
    "#     _, results[name] = cross_val_scores(\n",
    "#         model,\n",
    "#         X_train,\n",
    "#         y_train,\n",
    "#         X_val,\n",
    "#         y_val,\n",
    "#         return_train_score=True\n",
    "#     )\n",
    "\n",
    "#     print(f\"Done {name}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf6dc6-11cd-4370-b72a-5aef6a5a1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f52ea4-a1a7-41c4-9443-9ee6f3008c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After adding days differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933d897-644a-4fe8-bf66-dfb395846043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d6425-6fee-437d-bdbc-1d81de66a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After adding standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa89e5-a521-4cbc-a3fc-d04adf051f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e3dd8-bac6-4e6d-aceb-050154ec18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After converting some features to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09553f-dab6-4aab-89ff-37520efc24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60292f-544f-4b84-b404-8c843be9d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626e95b-4784-40ce-a463-e41dae3e1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd22838-0511-4aa0-b5a8-2221382b37e6",
   "metadata": {},
   "source": [
    "## FCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d3d9e1-e8c9-4e48-87cd-544c0295e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    FunctionTransformer,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from lightgbm.sklearn import LGBMRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d33b6d3-17fb-4ba9-8f6e-1ea2cfecb02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms, datasets, utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "import torch.utils.data as data\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36d83b9-30b9-4af9-a528-70849ba3262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train.csv\"\n",
    "test_path = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3adde0-ee18-4940-816a-7bcc0cb46c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_seed = 572\n",
    "# torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbeacb-a9a3-4d31-814d-b5f27416a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"floor_area\",\n",
    "    \"year_built\",\n",
    "    \"energy_star_rating\",\n",
    "    \"ELEVATION\",\n",
    "    \n",
    "    # \"january_min_temp\",\n",
    "    # \"january_avg_temp\",\n",
    "    # \"january_max_temp\",\n",
    "    # \"february_min_temp\",\n",
    "    # \"february_avg_temp\",\n",
    "    # \"february_max_temp\",\n",
    "    # \"march_min_temp\",\n",
    "    # \"march_avg_temp\",\n",
    "    # \"march_max_temp\",\n",
    "    # \"april_min_temp\",\n",
    "    # \"april_avg_temp\",\n",
    "    # \"april_max_temp\",\n",
    "    # \"may_min_temp\",\n",
    "    # \"may_avg_temp\",\n",
    "    # \"may_max_temp\",\n",
    "    # \"june_min_temp\",\n",
    "    # \"june_avg_temp\",\n",
    "    # \"june_max_temp\",\n",
    "    # \"july_min_temp\",\n",
    "    # \"july_avg_temp\",\n",
    "    # \"july_max_temp\",\n",
    "    # \"august_min_temp\",\n",
    "    # \"august_avg_temp\",\n",
    "    # \"august_max_temp\",\n",
    "    # \"september_min_temp\",\n",
    "    # \"september_avg_temp\",\n",
    "    # \"september_max_temp\",\n",
    "    # \"october_min_temp\",\n",
    "    # \"october_avg_temp\",\n",
    "    # \"october_max_temp\",\n",
    "    # \"november_min_temp\",\n",
    "    # \"november_avg_temp\",\n",
    "    # \"november_max_temp\",\n",
    "    # \"december_min_temp\",\n",
    "    # \"december_avg_temp\",\n",
    "    # \"december_max_temp\",\n",
    "    \n",
    "    \"cooling_degree_days\",\n",
    "    \"heating_degree_days\",\n",
    "    \"precipitation_inches\",\n",
    "    \"snowfall_inches\",\n",
    "    \"snowdepth_inches\",\n",
    "    \"avg_temp\",\n",
    "    \"days_below_30F\",\n",
    "    \"days_below_20F\",\n",
    "    \"days_below_10F\",\n",
    "    \"days_below_0F\",\n",
    "    \"days_above_80F\",\n",
    "    \"days_above_90F\",\n",
    "    \"days_above_100F\",\n",
    "    \"days_above_110F\",\n",
    "    \"max_wind_speed\",\n",
    "    \"days_with_fog\",\n",
    "    \"min_temp_std\",\n",
    "    \"max_temp_std\",\n",
    "    \"avg_temp_std\",\n",
    "    \"0-10\",\n",
    "    \"10-20\",\n",
    "    \"20-30\",\n",
    "    \"30-80\",\n",
    "    \"80-90\",\n",
    "    \"90-100\",\n",
    "    \"100-110\"\n",
    "] + min_temps + max_temps + avg_temps\n",
    "\n",
    "categorical_features = [\n",
    "    \"Year_Factor\",\n",
    "    \"State_Factor\",\n",
    "    \"building_class\",\n",
    "    \"facility_type\",\n",
    "    \"direction_max_wind_speed\",\n",
    "    \"direction_peak_wind_speed\"\n",
    "]\n",
    "\n",
    "drop_columns = [\n",
    "    \"id\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396fbcb-43ff-4fb9-b855-37d533ffc29f",
   "metadata": {},
   "source": [
    "# TODO Remove the limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f15d8d7f-a292-405c-8a71-77324d24b640",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numeric_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f81066e3986d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[0mfeature_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataprep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengineer_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m \u001b[0mfeature_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f81066e3986d>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m         )\n\u001b[0;32m    100\u001b[0m         column_transformer = make_column_transformer(\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mpipe_numeric_feats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numeric_features' is not defined"
     ]
    }
   ],
   "source": [
    "class Dataprep(Dataset):\n",
    "    \n",
    "    def __init__(self, train_path, test_path, size=0.1, is_train=True):\n",
    "        df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        TARGET_COLUMN = \"site_eui\"\n",
    "\n",
    "        self.is_train = is_train\n",
    "\n",
    "        train_df, val_df = train_test_split(\n",
    "            df,\n",
    "            test_size=0.1,\n",
    "            random_state=123\n",
    "        )\n",
    "\n",
    "        self.X_train, self.y_train = train_df.drop(columns=[TARGET_COLUMN]), train_df[TARGET_COLUMN]\n",
    "        self.X_val, self.y_val = val_df.drop(columns=[TARGET_COLUMN]), val_df[TARGET_COLUMN]\n",
    "        self.X_test = test_df\n",
    "\n",
    "\n",
    "    def engineer_features(self):\n",
    "        # Find Standard Deviation of min, max and avg temp among months\n",
    "        min_temps = [\n",
    "            \"january_min_temp\",\n",
    "            \"february_min_temp\",\n",
    "            \"march_min_temp\",\n",
    "            \"april_min_temp\",\n",
    "            \"may_min_temp\",\n",
    "            \"june_min_temp\",\n",
    "            \"july_min_temp\",\n",
    "            \"august_min_temp\",\n",
    "            \"september_min_temp\",\n",
    "            \"october_min_temp\",\n",
    "            \"november_min_temp\",\n",
    "            \"december_min_temp\"\n",
    "        ]\n",
    "\n",
    "        max_temps = [\n",
    "            \"january_max_temp\",\n",
    "            \"february_max_temp\",\n",
    "            \"march_max_temp\",\n",
    "            \"april_max_temp\",\n",
    "            \"may_max_temp\",\n",
    "            \"june_max_temp\",\n",
    "            \"july_max_temp\",\n",
    "            \"august_max_temp\",\n",
    "            \"september_max_temp\",\n",
    "            \"october_max_temp\",\n",
    "            \"november_max_temp\",\n",
    "            \"december_max_temp\"\n",
    "        ]\n",
    "\n",
    "        avg_temps = [\n",
    "            \"january_avg_temp\",\n",
    "            \"february_avg_temp\",\n",
    "            \"march_avg_temp\",\n",
    "            \"april_avg_temp\",\n",
    "            \"may_avg_temp\",\n",
    "            \"june_avg_temp\",\n",
    "            \"july_avg_temp\",\n",
    "            \"august_avg_temp\",\n",
    "            \"september_avg_temp\",\n",
    "            \"october_avg_temp\",\n",
    "            \"november_avg_temp\",\n",
    "            \"december_avg_temp\",\n",
    "        ]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"min_temp_std\"] = X[min_temps].T.std()\n",
    "            X[\"max_temp_std\"] = X[max_temps].T.std()\n",
    "            X[\"avg_temp_std\"] = X[avg_temps].T.std()\n",
    "\n",
    "        days_above_below = [\n",
    "            \"days_below_30F\",\n",
    "            \"days_below_20F\",\n",
    "            \"days_below_10F\",\n",
    "            \"days_below_0F\",\n",
    "            \"days_above_80F\",\n",
    "            \"days_above_90F\",\n",
    "            \"days_above_100F\",\n",
    "            \"days_above_110F\",\n",
    "        ]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"0-10\"] = X[\"days_below_10F\"] - X[\"days_below_0F\"]\n",
    "            X[\"10-20\"] = X[\"days_below_20F\"] - X[\"days_below_10F\"]\n",
    "            X[\"20-30\"] = X[\"days_below_30F\"] - X[\"days_below_20F\"]\n",
    "            X[\"80-90\"] = X[\"days_above_80F\"] - X[\"days_above_90F\"]\n",
    "            X[\"90-100\"] = X[\"days_above_90F\"] - X[\"days_above_100F\"]\n",
    "            X[\"100-110\"] = X[\"days_above_100F\"] - X[\"days_above_110F\"]\n",
    "            X[\"30-80\"] = (366 - X[days_above_below].sum(axis=1)).clip(lower=0)\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        pipe_numeric_feats = make_pipeline(\n",
    "           SimpleImputer(strategy=\"mean\"),\n",
    "           StandardScaler()\n",
    "        )\n",
    "        column_transformer = make_column_transformer(\n",
    "            (pipe_numeric_feats, numeric_features),\n",
    "            (OneHotEncoder(handle_unknown = \"ignore\"), categorical_features)\n",
    "        )\n",
    "        \n",
    "        self.X_train = column_transformer.fit_transform(self.X_train)\n",
    "        self.X_val = column_transformer.transform(self.X_val)\n",
    "        self.X_test = column_transformer.transform(self.X_test)\n",
    "\n",
    "        self.X_train = torch.tensor(self.X_train)\n",
    "        self.y_train = torch.tensor(self.y_train.values)\n",
    "        self.X_val = torch.tensor(self.X_val)\n",
    "        self.y_val = torch.tensor(self.y_val.values)\n",
    "        self.X_test = torch.tensor(self.X_test)        \n",
    "\n",
    "feature_set = Dataprep(train_path, test_path)\n",
    "feature_set.engineer_features()\n",
    "feature_set.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cbe6b8-105c-40d0-9006-057e5f3480af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_block(input_size, output_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, output_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2)\n",
    "    )\n",
    "\n",
    "class EnergyRegressor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            linear_block(input_size, 2 * input_size),\n",
    "            linear_block(2 * input_size, 3 * input_size),\n",
    "            linear_block(3 * input_size, input_size),\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X.to(device)\n",
    "        X = self.layers(X)\n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4a060-8855-40a2-8ffd-9c473b61e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(TensorDataset(feature_set.X_train, feature_set.y_train), batch_size=1, shuffle=True)\n",
    "validloader = DataLoader(TensorDataset(feature_set.X_val, feature_set.y_val), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d0fd6-46aa-4f44-9a09-2690602801e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnergyRegressor(feature_set.X_train.shape[1])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb876a-c8d8-4e88-af3c-793793c804e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2score(output, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - output) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "def mse(predictions, targets):\n",
    "    return torch.mean((predictions - targets) ** 2)\n",
    "        \n",
    "def rmse(predictions, targets):\n",
    "    return torch.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6c7e2-ee6f-438e-b876-4acb07358dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, criterion, optimizer, trainloader, validloader, epochs):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # train_batch_mse = []\n",
    "        # train_batch_rsme = []\n",
    "        # train_batch_r2 = []\n",
    "        # val_batch_mse = []\n",
    "        # val_batch_rsme = []\n",
    "        # val_batch_r2 = []\n",
    "        labels = []\n",
    "        preds = []\n",
    "        labels_val = []\n",
    "        preds_val = []\n",
    "        \n",
    "        for X, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X.type(torch.float32)) \n",
    "            loss = criterion(y_hat, y.type(torch.float32))\n",
    "            loss = loss.to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # mse_train = mse(y_hat, y.type(torch.float32))\n",
    "            # rsme_train = rmse(y_hat, y.type(torch.float32))\n",
    "            # r2_train = r2score(y_hat, y.type(torch.float32))\n",
    "            # train_batch_mse.append(mse_train)\n",
    "            # train_batch_rsme.append(rsme_train)\n",
    "            # train_batch_r2.append(r2_train)\n",
    "            labels.extend(y.tolist())\n",
    "            preds.extend(y_hat.tolist())\n",
    "\n",
    "        train_mse = mse(torch.FloatTensor(labels), torch.FloatTensor(preds))\n",
    "        train_rmse = rmse(torch.FloatTensor(labels), torch.FloatTensor(preds))\n",
    "        train_r2 = r2score(torch.FloatTensor(labels), torch.FloatTensor(preds))\n",
    "\n",
    "        # train_mse = torch.sum(torch.Tensor(train_batch_mse)) / len(trainloader)\n",
    "        # train_rsme = torch.sum(torch.Tensor(train_batch_rsme)) / len(trainloader)\n",
    "        # train_r2 = torch.sum(torch.Tensor(train_batch_r2)) / len(trainloader)\n",
    "\n",
    "        with torch.no_grad():  \n",
    "            for X_valid, y_valid in validloader:\n",
    "                X_valid = X_valid.to(device)\n",
    "                y_valid = y_valid.to(device)\n",
    "                y_hat_val = model(X_valid.type(torch.float32)) \n",
    "                # mse_val = mse(y_hat_val, y_valid.type(torch.float32))\n",
    "                # rsme_val = rmse(y_hat_val, y_valid.type(torch.float32))\n",
    "                # r2_val = r2score(y_hat_val, y_valid.type(torch.float32))\n",
    "                # val_batch_mse.append(mse_val)\n",
    "                # val_batch_rsme.append(rsme_val)\n",
    "                # val_batch_r2.append(r2_val)\n",
    "                labels_val.extend(y_valid.tolist())\n",
    "                preds_val.extend(y_hat_val.tolist())\n",
    "\n",
    "            val_mse = mse(torch.FloatTensor(labels_val), torch.FloatTensor(preds_val))\n",
    "            val_rsme = rmse(torch.FloatTensor(labels_val), torch.FloatTensor(preds_val))\n",
    "            val_r2 = r2score(torch.FloatTensor(labels_val), torch.FloatTensor(preds_val))\n",
    "            # val_mse = torch.sum(torch.Tensor(val_batch_mse)) / len(validloader)\n",
    "            # val_rsme = torch.sum(torch.Tensor(val_batch_rsme)) / len(validloader)\n",
    "            # val_r2 = torch.sum(torch.Tensor(val_batch_r2)) / len(validloader) \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: \")\n",
    "        print(f\"Train MSE: {train_mse}. Train RMSE: {train_mse}, Train R2: {train_r2}.\")\n",
    "        print(f\"Val MSE: {val_mse}, Val RMSE: {val_rsme}, Val R2: {val_r2}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b64b77-ed4b-4eae-bb43-e94cdc79e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    return model(X.type(torch.float32))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a33ca-87c3-46f5-9084-6a1425dcec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735cc7f-d2d5-4445-ab41-333d71ac1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "criterion = criterion.to(device)\n",
    "# optimizer = optimizer.to(device)\n",
    "trainer(model, criterion, optimizer, trainloader, validloader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa61b6e-b92a-4d41-b46e-1c7b326d4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(feature_set.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2f63b-8270-43c6-aaeb-4b62516ca1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98e57b-391f-47b5-af4e-04d6ff09c9de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_sup]",
   "language": "python",
   "name": "conda-env-env_sup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
