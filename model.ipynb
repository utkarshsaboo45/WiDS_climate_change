{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WiDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing the libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    FunctionTransformer,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from torchvision import transforms, datasets, utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "import torch.utils.data as data\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = \"../input/wids2022/train.csv\"\n",
    "# test_path = \"../input/wids2022/test.csv\"\n",
    "train_path = \"data/train.csv\"\n",
    "test_path = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataprep(Dataset):\n",
    "\n",
    "    def __init__(self, train_path, test_path, size=0.1, is_train=True):\n",
    "        df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        TARGET_COLUMN = \"site_eui\"\n",
    "\n",
    "        self.is_train = is_train\n",
    "\n",
    "        train_df, val_df = train_test_split(\n",
    "            df,\n",
    "            test_size=0.1,\n",
    "            random_state=123\n",
    "        )\n",
    "\n",
    "        self.X_train, self.y_train = train_df.drop(columns=[TARGET_COLUMN]), train_df[TARGET_COLUMN]\n",
    "        self.X_val, self.y_val = val_df.drop(columns=[TARGET_COLUMN]), val_df[TARGET_COLUMN]\n",
    "        self.X_test = test_df\n",
    "\n",
    "    def engineer_features(self):\n",
    "        # Find Standard Deviation of min, max and avg temp among months\n",
    "        min_temps = [\n",
    "            \"january_min_temp\",\n",
    "            \"february_min_temp\",\n",
    "            \"march_min_temp\",\n",
    "            \"april_min_temp\",\n",
    "            \"may_min_temp\",\n",
    "            \"june_min_temp\",\n",
    "            \"july_min_temp\",\n",
    "            \"august_min_temp\",\n",
    "            \"september_min_temp\",\n",
    "            \"october_min_temp\",\n",
    "            \"november_min_temp\",\n",
    "            \"december_min_temp\"\n",
    "        ]\n",
    "\n",
    "        max_temps = [\n",
    "            \"january_max_temp\",\n",
    "            \"february_max_temp\",\n",
    "            \"march_max_temp\",\n",
    "            \"april_max_temp\",\n",
    "            \"may_max_temp\",\n",
    "            \"june_max_temp\",\n",
    "            \"july_max_temp\",\n",
    "            \"august_max_temp\",\n",
    "            \"september_max_temp\",\n",
    "            \"october_max_temp\",\n",
    "            \"november_max_temp\",\n",
    "            \"december_max_temp\"\n",
    "        ]\n",
    "\n",
    "        avg_temps = [\n",
    "            \"january_avg_temp\",\n",
    "            \"february_avg_temp\",\n",
    "            \"march_avg_temp\",\n",
    "            \"april_avg_temp\",\n",
    "            \"may_avg_temp\",\n",
    "            \"june_avg_temp\",\n",
    "            \"july_avg_temp\",\n",
    "            \"august_avg_temp\",\n",
    "            \"september_avg_temp\",\n",
    "            \"october_avg_temp\",\n",
    "            \"november_avg_temp\",\n",
    "            \"december_avg_temp\",\n",
    "        ]\n",
    "\n",
    "        self.numeric_features = [\n",
    "            \"floor_area\",\n",
    "            \"year_built\",\n",
    "            \"energy_star_rating\",\n",
    "            \"ELEVATION\",\n",
    "            \"cooling_degree_days\",\n",
    "            \"heating_degree_days\",\n",
    "            \"precipitation_inches\",\n",
    "            \"snowfall_inches\",\n",
    "            \"snowdepth_inches\",\n",
    "            \"avg_temp\",\n",
    "            \"days_below_30F\",\n",
    "            \"days_below_20F\",\n",
    "            \"days_below_10F\",\n",
    "            \"days_below_0F\",\n",
    "            \"days_above_80F\",\n",
    "            \"days_above_90F\",\n",
    "            \"days_above_100F\",\n",
    "            \"days_above_110F\",\n",
    "            \"max_wind_speed\",\n",
    "            \"days_with_fog\",\n",
    "            \"building_age\",\n",
    "            \"min_temp_std\",\n",
    "            \"max_temp_std\",\n",
    "            \"avg_temp_std\",\n",
    "            \"0-10\",\n",
    "            \"10-20\",\n",
    "            \"20-30\",\n",
    "            \"30-80\",\n",
    "            \"80-90\",\n",
    "            \"90-100\",\n",
    "            \"100-110\"\n",
    "        ] + min_temps + max_temps + avg_temps\n",
    "\n",
    "        self.categorical_features = [\n",
    "            \"Year_Factor\",\n",
    "            \"State_Factor\",\n",
    "            \"building_class\",\n",
    "            \"facility_type\",\n",
    "            \"direction_max_wind_speed\",\n",
    "            \"direction_peak_wind_speed\"\n",
    "        ]\n",
    "\n",
    "        self.drop_columns = [\n",
    "            \"id\"\n",
    "        ]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"building_age\"] = 2022 - X[\"year_built\"]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"min_temp_std\"] = X[min_temps].T.std()\n",
    "            X[\"max_temp_std\"] = X[max_temps].T.std()\n",
    "            X[\"avg_temp_std\"] = X[avg_temps].T.std()\n",
    "\n",
    "        days_above_below = [\n",
    "            \"days_below_30F\",\n",
    "            \"days_below_20F\",\n",
    "            \"days_below_10F\",\n",
    "            \"days_below_0F\",\n",
    "            \"days_above_80F\",\n",
    "            \"days_above_90F\",\n",
    "            \"days_above_100F\",\n",
    "            \"days_above_110F\",\n",
    "        ]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"0-10\"] = X[\"days_below_10F\"] - X[\"days_below_0F\"]\n",
    "            X[\"10-20\"] = X[\"days_below_20F\"] - X[\"days_below_10F\"]\n",
    "            X[\"20-30\"] = X[\"days_below_30F\"] - X[\"days_below_20F\"]\n",
    "            X[\"80-90\"] = X[\"days_above_80F\"] - X[\"days_above_90F\"]\n",
    "            X[\"90-100\"] = X[\"days_above_90F\"] - X[\"days_above_100F\"]\n",
    "            X[\"100-110\"] = X[\"days_above_100F\"] - X[\"days_above_110F\"]\n",
    "            X[\"30-80\"] = (366 - X[days_above_below].sum(axis=1)).clip(lower=0)\n",
    "\n",
    "#         residential = [\n",
    "#             \"Multifamily_Uncategorized\",\n",
    "#             \"2to4_Unit_Building\",\n",
    "#             \"5plus_Unit_Building\",\n",
    "#             \"Religious_worship\",\n",
    "#             \"Parking_Garage\",\n",
    "#             \"Mixed_Use_Predominantly_Residential\"\n",
    "#         ]\n",
    "\n",
    "#         industrial = [\n",
    "#             \"Warehouse_Nonrefrigerated\",\n",
    "#             \"Warehouse_Distribution_or_Shipping_center\",\n",
    "#             \"Warehouse_Selfstorage\",\n",
    "#             \"Industrial\",\n",
    "#             \"Warehouse_Uncategorized\",\n",
    "#             \"Warehouse_Refrigerated\",\n",
    "#             \"Laboratory\",\n",
    "#             \"Data_Center\"\n",
    "#         ]\n",
    "\n",
    "#         commercial = list(\n",
    "#             set(self.X_train[\"facility_type\"].value_counts().index) -\n",
    "#             set(residential) - set(industrial)\n",
    "#         )\n",
    "\n",
    "#         temp = pd.concat([self.X_train[\"facility_type\"], feature_set.y_train], axis=1)\n",
    "#         convert_dic = dict(temp[[\"facility_type\", \"site_eui\"]].groupby(\"facility_type\")[\"site_eui\"].mean().sort_values())\n",
    "\n",
    "#         for X in [self.X_train, self.X_val, self.X_test]:\n",
    "#             for facility_type in [\n",
    "#                 \"Food\",\n",
    "#                 \"Education\",\n",
    "#                 \"Health_Care\",\n",
    "#                 \"Public_Assembly\",\n",
    "#                 \"Public_Safety\",\n",
    "#                 \"Lodging\",\n",
    "#                 \"Warehouse\",\n",
    "#                 \"Office\",\n",
    "#                 \"Service\",\n",
    "#                 \"Retail\"\n",
    "#             ]:\n",
    "#                 X[\"facility_type\"] = [\n",
    "#                     facility_type if f_type.lower().startswith(facility_type.lower())\n",
    "#                     else f_type\n",
    "#                     for f_type in X[\"facility_type\"]\n",
    "#                 ]\n",
    "# #             X.replace({\"facility_type\": convert_dic}, inplace=True)\n",
    "# #         #     X[\"facility_type\"] = [\n",
    "# #         #             \"commercial\" if f_type in commercial\n",
    "# #         #             else \"residential\" if f_type in residential\n",
    "# #         #             else \"industrial\"\n",
    "# #         #         for f_type in X[\"facility_type\"]]\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        pipe_numeric_feats = make_pipeline(\n",
    "           SimpleImputer(strategy=\"mean\"),\n",
    "           StandardScaler()\n",
    "        )\n",
    "        pipe_cat_feats = make_pipeline(\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "        )\n",
    "        self.column_transformer = make_column_transformer(\n",
    "            (pipe_numeric_feats, self.numeric_features),\n",
    "            (pipe_cat_feats, self.categorical_features)\n",
    "        )\n",
    "\n",
    "        self.X_train_raw = self.X_train\n",
    "        self.X_val_raw = self.X_val\n",
    "        self.X_test_raw = self.X_test\n",
    "        self.X_train = self.column_transformer.fit_transform(self.X_train)\n",
    "        self.X_val = self.column_transformer.transform(self.X_val)\n",
    "        self.X_test = self.column_transformer.transform(self.X_test)\n",
    "\n",
    "        self.X_train_tensor = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        self.y_train_tensor = torch.tensor(self.y_train.values, dtype=torch.float32)\n",
    "        self.X_val_tensor = torch.tensor(self.X_val, dtype=torch.float32)\n",
    "        self.y_val_tensor = torch.tensor(self.y_val.values, dtype=torch.float32)\n",
    "        self.X_test_tensor = torch.tensor(self.X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_set = Dataprep(train_path, test_path)\n",
    "feature_set.engineer_features()\n",
    "feature_set.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Temp zone #################################################\n",
    "\n",
    "# Apply imputation in all columns\n",
    "\n",
    "# Tried: X_train[\"facility_type\"].value_counts() -> Categorize in 3-4 categories\n",
    "# energy level / floor area group by mean and variance\n",
    "\n",
    "# Time series seasonal component in the monthly data -> Try feeding to RNNs\n",
    "# Take three month windows to calculate average -> Repeat it to narrow 12 features down to 1 or try SVD\n",
    "\n",
    "# use site_eui to order facility_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse(predictions, targets):\n",
    "    return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "\n",
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "def r2score_torch(predictions, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - predictions) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "\n",
    "def mse_torch(predictions, targets):\n",
    "    return torch.mean((predictions - targets) ** 2)\n",
    "\n",
    "\n",
    "def rmse_torch(predictions, targets):\n",
    "    return torch.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68181, 160)\n",
      "(7576, 160)\n",
      "(68181,)\n",
      "(7576,)\n"
     ]
    }
   ],
   "source": [
    "for dt in [\n",
    "    feature_set.X_train,\n",
    "    feature_set.X_val,\n",
    "    feature_set.y_train,\n",
    "    feature_set.y_val\n",
    "]:\n",
    "    print(dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_val_scores(model, X_train, y_train, X_val, y_val, return_train_score=False):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    score_dict = {\n",
    "        \"r2_val\": model.score(X_val, y_val),\n",
    "        \"mse_val\": mse(y_val, y_val_pred),\n",
    "        \"rmse_val\": rmse(y_val, y_val_pred),\n",
    "        \"mape_val\": mape(y_val, y_val_pred)\n",
    "    }\n",
    "\n",
    "    if return_train_score:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        score_dict[\"r2_train\"] = model.score(X_train, y_train)\n",
    "        score_dict[\"mse_train\"] = mse(y_train, y_train_pred)\n",
    "        score_dict[\"rmse_train\"] = rmse(y_train, y_train_pred)\n",
    "        score_dict[\"mape_train\"] = mape(y_train, y_train_pred)\n",
    "\n",
    "    scores_result = pd.Series(score_dict)\n",
    "\n",
    "    return model, scores_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(feature_set.column_transformer, Ridge(max_iter=10000))\n",
    "pipe_lasso = make_pipeline(feature_set.column_transformer, Lasso())\n",
    "pipe_rf = make_pipeline(feature_set.column_transformer, RandomForestRegressor())\n",
    "pipe_xgb = make_pipeline(feature_set.column_transformer, XGBRegressor(verbosity=0))#, eta=0.01, max_depth=7, n_estimators=1000))\n",
    "pipe_lgbm = make_pipeline(feature_set.column_transformer, LGBMRegressor())\n",
    "pipe_catboost = make_pipeline(feature_set.column_transformer, CatBoostRegressor(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def train(models, results):\n",
    "    for name, model in models.items():\n",
    "        print(f\"Start {name}!\")\n",
    "        start_time = time.time()\n",
    "        _, results[name] = cross_val_scores(\n",
    "            model,\n",
    "            feature_set.X_train_raw,\n",
    "            feature_set.y_train,\n",
    "            feature_set.X_val_raw,\n",
    "            feature_set.y_val,\n",
    "            return_train_score=True\n",
    "        )\n",
    "\n",
    "        print(f\"Done {name} in {round(time.time() - start_time)} secs!\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape\": mape_scorer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": pipe_ridge,\n",
    "    \"Lasso\": pipe_lasso,\n",
    "    \"Random Forest\": pipe_rf,\n",
    "    \"XGB\": pipe_xgb,\n",
    "    \"LGBM\": pipe_lgbm,\n",
    "    \"Cat Boost\": pipe_catboost,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T11:03:41.627603Z",
     "iopub.status.busy": "2022-02-23T11:03:41.627335Z"
    }
   },
   "outputs": [],
   "source": [
    "results = train(models, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68181, 160)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(Ridge(), min_features_to_select=120, n_jobs=-1)\n",
    "\n",
    "pipe_xgb_rfecv = make_pipeline(\n",
    "    feature_set.column_transformer, rfecv, XGBRegressor(verbosity=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feats = PolynomialFeatures(degree=2)\n",
    "\n",
    "pipe_poly_ridge = make_pipeline(\n",
    "    feature_set.column_transformer, rfecv, poly_feats, Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rfe_poly_ridge = {\n",
    "    \"XGB rfecv\": pipe_xgb_rfecv,\n",
    "    # \"Poly Ridge\": pipe_poly_ridge\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start XGB rfecv!\n",
      "Done XGB rfecv in 22 secs!\n"
     ]
    }
   ],
   "source": [
    "results = train(models_rfe_poly_ridge, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB rfecv</th>\n",
       "      <th>Poly Ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.514630</td>\n",
       "      <td>0.381328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_val</th>\n",
       "      <td>1506.993403</td>\n",
       "      <td>1920.875815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_val</th>\n",
       "      <td>38.820013</td>\n",
       "      <td>43.827797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_val</th>\n",
       "      <td>44.149664</td>\n",
       "      <td>48.838148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.631292</td>\n",
       "      <td>0.415892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_train</th>\n",
       "      <td>1263.082954</td>\n",
       "      <td>2000.981302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>35.539878</td>\n",
       "      <td>44.732329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_train</th>\n",
       "      <td>45.894592</td>\n",
       "      <td>55.636894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              XGB rfecv   Poly Ridge\n",
       "r2_val         0.514630     0.381328\n",
       "mse_val     1506.993403  1920.875815\n",
       "rmse_val      38.820013    43.827797\n",
       "mape_val      44.149664    48.838148\n",
       "r2_train       0.631292     0.415892\n",
       "mse_train   1263.082954  2000.981302\n",
       "rmse_train    35.539878    44.732329\n",
       "mape_train    45.894592    55.636894"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam Tune Random Forest \n",
    "\n",
    "params_rf = {\n",
    "    'randomforestregressor__n_estimators': [10, 100, 500, 1000],\n",
    "    'randomforestregressor__max_depth': [5, 10, 12],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf = RandomizedSearchCV(\n",
    "    pipe_rf,\n",
    "    params_rf,\n",
    "    n_jobs=-1,\n",
    "    n_iter=20,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metrics,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(random_search_rf.cv_results_)\n",
    "# pd.DataFrame(random_search.cv_results_)[[\n",
    "#         \"mean_fit_time\",\n",
    "#         \"mean_score_time\",\n",
    "#         \"param_ridge__alpha\",\n",
    "#         \"mean_train_neg RMSE\",\n",
    "#         \"std_train_neg RMSE\",\n",
    "#         \"mean_test_mape\",\n",
    "#         \"mean_train_mape\",\n",
    "#         \"mean_test_r2\",\n",
    "#         \"mean_train_r2\"\n",
    "#     ]\n",
    "# ].sort_values(by='mean_test_r2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgbm = {\n",
    "    'lgbmregressor__n_estimators': [10, 100, 1000],\n",
    "    'lgbmregressor__max_depth': [5, 10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    pipe_lgbm,\n",
    "    params_lgbm,\n",
    "    n_jobs=-1,\n",
    "    n_iter=20,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metrics,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(random_search_lgbm.cv_results_)\n",
    "pd.DataFrame(random_search_lgbm.cv_results_)[[\n",
    "        \"mean_fit_time\",\n",
    "        \"mean_score_time\",\n",
    "        \"params\",\n",
    "        \"mean_train_neg RMSE\",\n",
    "        \"mean_test_neg RMSE\",\n",
    "        \"mean_test_mape\",\n",
    "        \"mean_train_mape\",\n",
    "        \"mean_test_r2\",\n",
    "        \"mean_train_r2\"\n",
    "    ]\n",
    "].sort_values(by=\"mean_test_r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_lgbm.best_params_)\n",
    "print(random_search_lgbm.best_score_)\n",
    "# {'lgbmregressor__n_estimators': 1000, 'lgbmregressor__max_depth': 20}\n",
    "# 0.49699611783887543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperparamTune XGBoost\n",
    "params_xgb = {\n",
    "    'xgbregressor__n_estimators': [10, 100, 1000],\n",
    "    'xgbregressor__max_depth': [3, 5, 7, 12],\n",
    "    'xgbregressor__eta': [0.01, 0.03, 0.01, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_xgb = RandomizedSearchCV(\n",
    "    pipe_xgb,\n",
    "    params_xgb,\n",
    "    n_jobs=-1,\n",
    "    n_iter=20,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metrics,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer()),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['floor_area',\n",
       "                                                                                'year_built',\n",
       "                                                                                'energy_star_rating',\n",
       "                                                                                'ELEVATION',\n",
       "                                                                                'cooling_degree_days',\n",
       "                                                                                'heating_degree_days',\n",
       "                                                                                'precipitation_inches',\n",
       "                                                                                'snowfall_inches',\n",
       "                                                                                'snow...\n",
       "                                                           tree_method=None,\n",
       "                                                           validate_parameters=None,\n",
       "                                                           verbosity=0))]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'xgbregressor__eta': [0.01, 0.03, 0.01,\n",
       "                                                              0.3],\n",
       "                                        'xgbregressor__max_depth': [3, 5, 7,\n",
       "                                                                    12],\n",
       "                                        'xgbregressor__n_estimators': [10, 100,\n",
       "                                                                       1000]},\n",
       "                   refit='r2', return_train_score=True,\n",
       "                   scoring={'mape': make_scorer(mape, greater_is_better=False),\n",
       "                            'neg RMSE': 'neg_root_mean_squared_error',\n",
       "                            'r2': 'r2'})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_xgb.fit(feature_set.X_train_raw, feature_set.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_neg RMSE</th>\n",
       "      <th>mean_test_neg RMSE</th>\n",
       "      <th>mean_test_mape</th>\n",
       "      <th>mean_train_mape</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>574.659637</td>\n",
       "      <td>0.307976</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-10.903566</td>\n",
       "      <td>-38.522429</td>\n",
       "      <td>-40.791748</td>\n",
       "      <td>-15.783641</td>\n",
       "      <td>0.565928</td>\n",
       "      <td>0.965286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356.662588</td>\n",
       "      <td>0.292019</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-19.550576</td>\n",
       "      <td>-38.947062</td>\n",
       "      <td>-43.210219</td>\n",
       "      <td>-28.687540</td>\n",
       "      <td>0.556450</td>\n",
       "      <td>0.888399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1175.295331</td>\n",
       "      <td>0.454385</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-20.642279</td>\n",
       "      <td>-39.257042</td>\n",
       "      <td>-42.864195</td>\n",
       "      <td>-29.014406</td>\n",
       "      <td>0.549508</td>\n",
       "      <td>0.875529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>563.405348</td>\n",
       "      <td>0.279453</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-32.168396</td>\n",
       "      <td>-40.598057</td>\n",
       "      <td>-47.114703</td>\n",
       "      <td>-42.491214</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>0.697873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49.140569</td>\n",
       "      <td>0.167951</td>\n",
       "      <td>{'xgbregressor__n_estimators': 100, 'xgbregres...</td>\n",
       "      <td>-30.877795</td>\n",
       "      <td>-40.947238</td>\n",
       "      <td>-47.232692</td>\n",
       "      <td>-41.330082</td>\n",
       "      <td>0.509899</td>\n",
       "      <td>0.721631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307.116411</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-36.729475</td>\n",
       "      <td>-42.003204</td>\n",
       "      <td>-49.669794</td>\n",
       "      <td>-46.950941</td>\n",
       "      <td>0.484413</td>\n",
       "      <td>0.606148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628.822790</td>\n",
       "      <td>0.373404</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-36.973773</td>\n",
       "      <td>-42.168410</td>\n",
       "      <td>-50.787486</td>\n",
       "      <td>-48.621630</td>\n",
       "      <td>0.480431</td>\n",
       "      <td>0.600853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>134.556621</td>\n",
       "      <td>0.192685</td>\n",
       "      <td>{'xgbregressor__n_estimators': 100, 'xgbregres...</td>\n",
       "      <td>-35.357155</td>\n",
       "      <td>-42.826538</td>\n",
       "      <td>-48.781719</td>\n",
       "      <td>-45.436484</td>\n",
       "      <td>0.463993</td>\n",
       "      <td>0.635034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>319.171959</td>\n",
       "      <td>0.258908</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-40.370169</td>\n",
       "      <td>-43.375100</td>\n",
       "      <td>-53.796786</td>\n",
       "      <td>-52.469732</td>\n",
       "      <td>0.450265</td>\n",
       "      <td>0.524188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.446537</td>\n",
       "      <td>0.161568</td>\n",
       "      <td>{'xgbregressor__n_estimators': 100, 'xgbregres...</td>\n",
       "      <td>-40.689313</td>\n",
       "      <td>-43.545180</td>\n",
       "      <td>-52.544649</td>\n",
       "      <td>-51.480214</td>\n",
       "      <td>0.445782</td>\n",
       "      <td>0.516650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>208.849917</td>\n",
       "      <td>0.208243</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>-41.512844</td>\n",
       "      <td>-43.557148</td>\n",
       "      <td>-53.328681</td>\n",
       "      <td>-52.398499</td>\n",
       "      <td>0.445534</td>\n",
       "      <td>0.496895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.814026</td>\n",
       "      <td>0.177924</td>\n",
       "      <td>{'xgbregressor__n_estimators': 100, 'xgbregres...</td>\n",
       "      <td>-41.500443</td>\n",
       "      <td>-44.452413</td>\n",
       "      <td>-54.142999</td>\n",
       "      <td>-53.190299</td>\n",
       "      <td>0.422630</td>\n",
       "      <td>0.497165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.428555</td>\n",
       "      <td>0.177326</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-44.098923</td>\n",
       "      <td>-45.883027</td>\n",
       "      <td>-58.349148</td>\n",
       "      <td>-57.825912</td>\n",
       "      <td>0.384877</td>\n",
       "      <td>0.432283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.710750</td>\n",
       "      <td>0.176927</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-47.545003</td>\n",
       "      <td>-47.980376</td>\n",
       "      <td>-64.404871</td>\n",
       "      <td>-64.201026</td>\n",
       "      <td>0.327305</td>\n",
       "      <td>0.340074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156.619314</td>\n",
       "      <td>0.264692</td>\n",
       "      <td>{'xgbregressor__n_estimators': 100, 'xgbregres...</td>\n",
       "      <td>-52.617512</td>\n",
       "      <td>-55.537554</td>\n",
       "      <td>-49.853121</td>\n",
       "      <td>-48.740556</td>\n",
       "      <td>0.098687</td>\n",
       "      <td>0.191740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.848283</td>\n",
       "      <td>0.193084</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-80.674460</td>\n",
       "      <td>-80.973681</td>\n",
       "      <td>-72.783864</td>\n",
       "      <td>-72.747314</td>\n",
       "      <td>-0.916456</td>\n",
       "      <td>-0.900032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.492067</td>\n",
       "      <td>0.192086</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-92.995190</td>\n",
       "      <td>-93.184361</td>\n",
       "      <td>-87.952955</td>\n",
       "      <td>-87.989339</td>\n",
       "      <td>-1.538185</td>\n",
       "      <td>-1.524690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.801111</td>\n",
       "      <td>0.157579</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-93.297074</td>\n",
       "      <td>-93.382187</td>\n",
       "      <td>-87.544462</td>\n",
       "      <td>-87.553366</td>\n",
       "      <td>-1.548958</td>\n",
       "      <td>-1.541113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.925825</td>\n",
       "      <td>0.190690</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-93.486842</td>\n",
       "      <td>-93.528787</td>\n",
       "      <td>-87.064214</td>\n",
       "      <td>-87.071900</td>\n",
       "      <td>-1.556995</td>\n",
       "      <td>-1.551459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.814073</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>{'xgbregressor__n_estimators': 10, 'xgbregress...</td>\n",
       "      <td>-93.822747</td>\n",
       "      <td>-93.836018</td>\n",
       "      <td>-86.846406</td>\n",
       "      <td>-86.845913</td>\n",
       "      <td>-1.573760</td>\n",
       "      <td>-1.569822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  \\\n",
       "13     574.659637         0.307976   \n",
       "1      356.662588         0.292019   \n",
       "2     1175.295331         0.454385   \n",
       "17     563.405348         0.279453   \n",
       "8       49.140569         0.167951   \n",
       "4      307.116411         0.296407   \n",
       "0      628.822790         0.373404   \n",
       "10     134.556621         0.192685   \n",
       "18     319.171959         0.258908   \n",
       "11      17.446537         0.161568   \n",
       "14     208.849917         0.208243   \n",
       "6       59.814026         0.177924   \n",
       "5        4.428555         0.177326   \n",
       "16       2.710750         0.176927   \n",
       "15     156.619314         0.264692   \n",
       "9        6.848283         0.193084   \n",
       "19      19.492067         0.192086   \n",
       "7        6.801111         0.157579   \n",
       "3        4.925825         0.190690   \n",
       "12       2.814073         0.160770   \n",
       "\n",
       "                                               params  mean_train_neg RMSE  \\\n",
       "13  {'xgbregressor__n_estimators': 1000, 'xgbregre...           -10.903566   \n",
       "1   {'xgbregressor__n_estimators': 1000, 'xgbregre...           -19.550576   \n",
       "2   {'xgbregressor__n_estimators': 1000, 'xgbregre...           -20.642279   \n",
       "17  {'xgbregressor__n_estimators': 1000, 'xgbregre...           -32.168396   \n",
       "8   {'xgbregressor__n_estimators': 100, 'xgbregres...           -30.877795   \n",
       "4   {'xgbregressor__n_estimators': 1000, 'xgbregre...           -36.729475   \n",
       "0   {'xgbregressor__n_estimators': 1000, 'xgbregre...           -36.973773   \n",
       "10  {'xgbregressor__n_estimators': 100, 'xgbregres...           -35.357155   \n",
       "18  {'xgbregressor__n_estimators': 1000, 'xgbregre...           -40.370169   \n",
       "11  {'xgbregressor__n_estimators': 100, 'xgbregres...           -40.689313   \n",
       "14  {'xgbregressor__n_estimators': 1000, 'xgbregre...           -41.512844   \n",
       "6   {'xgbregressor__n_estimators': 100, 'xgbregres...           -41.500443   \n",
       "5   {'xgbregressor__n_estimators': 10, 'xgbregress...           -44.098923   \n",
       "16  {'xgbregressor__n_estimators': 10, 'xgbregress...           -47.545003   \n",
       "15  {'xgbregressor__n_estimators': 100, 'xgbregres...           -52.617512   \n",
       "9   {'xgbregressor__n_estimators': 10, 'xgbregress...           -80.674460   \n",
       "19  {'xgbregressor__n_estimators': 10, 'xgbregress...           -92.995190   \n",
       "7   {'xgbregressor__n_estimators': 10, 'xgbregress...           -93.297074   \n",
       "3   {'xgbregressor__n_estimators': 10, 'xgbregress...           -93.486842   \n",
       "12  {'xgbregressor__n_estimators': 10, 'xgbregress...           -93.822747   \n",
       "\n",
       "    mean_test_neg RMSE  mean_test_mape  mean_train_mape  mean_test_r2  \\\n",
       "13          -38.522429      -40.791748       -15.783641      0.565928   \n",
       "1           -38.947062      -43.210219       -28.687540      0.556450   \n",
       "2           -39.257042      -42.864195       -29.014406      0.549508   \n",
       "17          -40.598057      -47.114703       -42.491214      0.518292   \n",
       "8           -40.947238      -47.232692       -41.330082      0.509899   \n",
       "4           -42.003204      -49.669794       -46.950941      0.484413   \n",
       "0           -42.168410      -50.787486       -48.621630      0.480431   \n",
       "10          -42.826538      -48.781719       -45.436484      0.463993   \n",
       "18          -43.375100      -53.796786       -52.469732      0.450265   \n",
       "11          -43.545180      -52.544649       -51.480214      0.445782   \n",
       "14          -43.557148      -53.328681       -52.398499      0.445534   \n",
       "6           -44.452413      -54.142999       -53.190299      0.422630   \n",
       "5           -45.883027      -58.349148       -57.825912      0.384877   \n",
       "16          -47.980376      -64.404871       -64.201026      0.327305   \n",
       "15          -55.537554      -49.853121       -48.740556      0.098687   \n",
       "9           -80.973681      -72.783864       -72.747314     -0.916456   \n",
       "19          -93.184361      -87.952955       -87.989339     -1.538185   \n",
       "7           -93.382187      -87.544462       -87.553366     -1.548958   \n",
       "3           -93.528787      -87.064214       -87.071900     -1.556995   \n",
       "12          -93.836018      -86.846406       -86.845913     -1.573760   \n",
       "\n",
       "    mean_train_r2  \n",
       "13       0.965286  \n",
       "1        0.888399  \n",
       "2        0.875529  \n",
       "17       0.697873  \n",
       "8        0.721631  \n",
       "4        0.606148  \n",
       "0        0.600853  \n",
       "10       0.635034  \n",
       "18       0.524188  \n",
       "11       0.516650  \n",
       "14       0.496895  \n",
       "6        0.497165  \n",
       "5        0.432283  \n",
       "16       0.340074  \n",
       "15       0.191740  \n",
       "9       -0.900032  \n",
       "19      -1.524690  \n",
       "7       -1.541113  \n",
       "3       -1.551459  \n",
       "12      -1.569822  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(random_search_xgb.cv_results_)\n",
    "pd.DataFrame(random_search_xgb.cv_results_)[[\n",
    "        \"mean_fit_time\",\n",
    "        \"mean_score_time\",\n",
    "        \"params\",\n",
    "        \"mean_train_neg RMSE\",\n",
    "        \"mean_test_neg RMSE\",\n",
    "        \"mean_test_mape\",\n",
    "        \"mean_train_mape\",\n",
    "        \"mean_test_r2\",\n",
    "        \"mean_train_r2\"\n",
    "    ]\n",
    "].sort_values(by=\"mean_test_r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xgbregressor__n_estimators': 1000, 'xgbregressor__max_depth': 7, 'xgbregressor__eta': 0.3}\n",
      "0.5659283801380433\n"
     ]
    }
   ],
   "source": [
    "print(random_search_xgb.best_params_)\n",
    "print(random_search_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_selected = {\n",
    "    \"Ridge\": pipe_ridge,\n",
    "    \"XGB\": pipe_xgb,\n",
    "    \"LGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost\n",
    "#     \"<>_rfecv\": pipe_<>_rfecv,\n",
    "#     \"Poly Ridge\": pipe_poly_ridge,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(list(models_selected.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Stacking!\n",
      "Done Stacking in 166 secs!\n"
     ]
    }
   ],
   "source": [
    "name = \"Stacking\"\n",
    "\n",
    "print(f\"Start {name}!\")\n",
    "start_time = time.time()\n",
    "\n",
    "_, results[name] = cross_val_scores(\n",
    "    stacking_model,\n",
    "    feature_set.X_train_raw,\n",
    "    feature_set.y_train,\n",
    "    feature_set.X_val_raw,\n",
    "    feature_set.y_val,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Done {name} in {round(time.time() - start_time)} secs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB rfecv</th>\n",
       "      <th>Poly Ridge</th>\n",
       "      <th>Stacking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.514630</td>\n",
       "      <td>0.381328</td>\n",
       "      <td>0.546436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_val</th>\n",
       "      <td>1506.993403</td>\n",
       "      <td>1920.875815</td>\n",
       "      <td>1408.242515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_val</th>\n",
       "      <td>38.820013</td>\n",
       "      <td>43.827797</td>\n",
       "      <td>37.526557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_val</th>\n",
       "      <td>44.149664</td>\n",
       "      <td>48.838148</td>\n",
       "      <td>41.849547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.631292</td>\n",
       "      <td>0.415892</td>\n",
       "      <td>0.667832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_train</th>\n",
       "      <td>1263.082954</td>\n",
       "      <td>2000.981302</td>\n",
       "      <td>1137.908182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>35.539878</td>\n",
       "      <td>44.732329</td>\n",
       "      <td>33.732895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_train</th>\n",
       "      <td>45.894592</td>\n",
       "      <td>55.636894</td>\n",
       "      <td>43.783458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              XGB rfecv   Poly Ridge     Stacking\n",
       "r2_val         0.514630     0.381328     0.546436\n",
       "mse_val     1506.993403  1920.875815  1408.242515\n",
       "rmse_val      38.820013    43.827797    37.526557\n",
       "mape_val      44.149664    48.838148    41.849547\n",
       "r2_train       0.631292     0.415892     0.667832\n",
       "mse_train   1263.082954  2000.981302  1137.908182\n",
       "rmse_train    35.539878    44.732329    33.732895\n",
       "mape_train    45.894592    55.636894    43.783458"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_block(input_size, output_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, output_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2)\n",
    "    )\n",
    "\n",
    "class Extractlastcell(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out, _ = x\n",
    "        return out[-1]\n",
    "\n",
    "\n",
    "class EnergyRegressor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EnergyRegressor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=2 * input_size, num_layers=2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.layers = nn.Sequential(\n",
    "            linear_block(2 * input_size, 3 * input_size),\n",
    "            linear_block(3 * input_size, 5 * input_size),\n",
    "            linear_block(5 * input_size, 10 * input_size),\n",
    "            linear_block(10 * input_size, 7 * input_size),\n",
    "            linear_block(7 * input_size, 5 * input_size),\n",
    "            linear_block(5 * input_size, 3 * input_size),\n",
    "            linear_block(3 * input_size, input_size),\n",
    "            nn.Linear(input_size, 1000),\n",
    "            nn.Linear(1000, 700),\n",
    "            nn.Linear(700, 400), \n",
    "            nn.Linear(400, 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.to(device)\n",
    "        # X (sequence length, batch size, input size)\n",
    "        X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "        X, _ = self.lstm(X)\n",
    "        X = X[-1]\n",
    "        X = self.tanh(X)\n",
    "        X = self.layers(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(TensorDataset(feature_set.X_train_tensor, feature_set.y_train_tensor), batch_size=32, shuffle=True)\n",
    "validloader = DataLoader(TensorDataset(feature_set.X_val_tensor, feature_set.y_val_tensor), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnergyRegressor(feature_set.X_train_tensor.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, criterion, optimizer, trainloader, validloader, epochs):\n",
    "    train_mse = 0\n",
    "    train_rmse = 0\n",
    "    train_r2 = 0\n",
    "    val_mse = 0\n",
    "    val_rmse = 0\n",
    "    val_r2 = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_batch_mse = []\n",
    "        train_batch_rmse = []\n",
    "        train_batch_r2 = []\n",
    "        val_batch_mse = []\n",
    "        val_batch_rmse = []\n",
    "        val_batch_r2 = []\n",
    "\n",
    "        model.train(True)\n",
    "\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X).flatten()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss = loss.to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            mse_train = mse_torch(y_hat, y)\n",
    "            rmse_train = rmse_torch(y_hat, y)\n",
    "            r2_train = r2score_torch(y_hat, y)\n",
    "            train_batch_mse.append(mse_train)\n",
    "            train_batch_rmse.append(rmse_train)\n",
    "            train_batch_r2.append(r2_train)\n",
    "        \n",
    "        train_mse = torch.sum(torch.Tensor(train_batch_mse)) / len(trainloader)\n",
    "        train_rmse = torch.sum(torch.Tensor(train_batch_rmse)) / len(trainloader)\n",
    "        train_r2 = torch.sum(torch.Tensor(train_batch_r2)) / len(trainloader)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_valid, y_valid in validloader:\n",
    "                X_valid = X_valid.to(device)\n",
    "                y_valid = y_valid.to(device).flatten()\n",
    "                y_hat_val = model(X_valid)\n",
    "                mse_val = mse_torch(y_hat_val, y_valid)\n",
    "                rmse_val = rmse_torch(y_hat_val, y_valid)\n",
    "                r2_val = r2score_torch(y_hat_val, y_valid)\n",
    "                val_batch_mse.append(mse_val)\n",
    "                val_batch_rmse.append(rmse_val)\n",
    "                val_batch_r2.append(r2_val)\n",
    "            val_mse = torch.sum(torch.Tensor(val_batch_mse)) / len(validloader)\n",
    "            val_rmse = torch.sum(torch.Tensor(val_batch_rmse)) / len(validloader)\n",
    "            val_r2 = torch.sum(torch.Tensor(val_batch_r2)) / len(validloader) \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}:\\tTrain:\\tMSE: {round(train_mse.item(), 4)}. RMSE: {round(train_rmse.item(), 4)}, R2: {round(train_r2.item(), 4)}.\")\n",
    "        print(f\"\\t\\tVal:\\tMSE: {round(val_mse.item(), 4)}, RMSE: {round(val_rmse.item(), 4)}, R2: {round(val_r2.item(), 4)}.\")\n",
    "        print(\"-\" * 80)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = criterion.to(device)\n",
    "trained_model = trainer(model, criterion, optimizer, trainloader, validloader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    return model(X.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(trained_model, feature_set.X_test_tensor)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"id\": feature_set.X_test_raw[\"id\"],\n",
    "               \"site_eui\": predictions.cpu().detach().numpy().flatten()}\n",
    "pd.DataFrame(results_dict).set_index(\"id\").to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:climatechange]",
   "language": "python",
   "name": "conda-env-climatechange-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
