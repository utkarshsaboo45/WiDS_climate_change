{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WiDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing the libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    FunctionTransformer,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from torchvision import transforms, datasets, utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import MSELoss\n",
    "import torch.utils.data as data\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_Factor</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_Factor</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_class</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facility_type</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor_area</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_built</th>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy_star_rating</th>\n",
       "      <td>26709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATION</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>april_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>april_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>april_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>june_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>june_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>june_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>july_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>july_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>july_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>august_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>august_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>august_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>september_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>september_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>september_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>october_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>october_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>october_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>november_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>november_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>november_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>december_min_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>december_avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>december_max_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooling_degree_days</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heating_degree_days</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipitation_inches</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowfall_inches</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snowdepth_inches</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_temp</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_below_30F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_below_20F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_below_10F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_below_0F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_above_80F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_above_90F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_above_100F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_above_110F</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_max_wind_speed</th>\n",
       "      <td>41082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direction_peak_wind_speed</th>\n",
       "      <td>41811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_wind_speed</th>\n",
       "      <td>41082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_with_fog</th>\n",
       "      <td>45796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_eui</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "Year_Factor                    0\n",
       "State_Factor                   0\n",
       "building_class                 0\n",
       "facility_type                  0\n",
       "floor_area                     0\n",
       "year_built                  1837\n",
       "energy_star_rating         26709\n",
       "ELEVATION                      0\n",
       "january_min_temp               0\n",
       "january_avg_temp               0\n",
       "january_max_temp               0\n",
       "february_min_temp              0\n",
       "february_avg_temp              0\n",
       "february_max_temp              0\n",
       "march_min_temp                 0\n",
       "march_avg_temp                 0\n",
       "march_max_temp                 0\n",
       "april_min_temp                 0\n",
       "april_avg_temp                 0\n",
       "april_max_temp                 0\n",
       "may_min_temp                   0\n",
       "may_avg_temp                   0\n",
       "may_max_temp                   0\n",
       "june_min_temp                  0\n",
       "june_avg_temp                  0\n",
       "june_max_temp                  0\n",
       "july_min_temp                  0\n",
       "july_avg_temp                  0\n",
       "july_max_temp                  0\n",
       "august_min_temp                0\n",
       "august_avg_temp                0\n",
       "august_max_temp                0\n",
       "september_min_temp             0\n",
       "september_avg_temp             0\n",
       "september_max_temp             0\n",
       "october_min_temp               0\n",
       "october_avg_temp               0\n",
       "october_max_temp               0\n",
       "november_min_temp              0\n",
       "november_avg_temp              0\n",
       "november_max_temp              0\n",
       "december_min_temp              0\n",
       "december_avg_temp              0\n",
       "december_max_temp              0\n",
       "cooling_degree_days            0\n",
       "heating_degree_days            0\n",
       "precipitation_inches           0\n",
       "snowfall_inches                0\n",
       "snowdepth_inches               0\n",
       "avg_temp                       0\n",
       "days_below_30F                 0\n",
       "days_below_20F                 0\n",
       "days_below_10F                 0\n",
       "days_below_0F                  0\n",
       "days_above_80F                 0\n",
       "days_above_90F                 0\n",
       "days_above_100F                0\n",
       "days_above_110F                0\n",
       "direction_max_wind_speed   41082\n",
       "direction_peak_wind_speed  41811\n",
       "max_wind_speed             41082\n",
       "days_with_fog              45796\n",
       "site_eui                       0\n",
       "id                             0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "pd.DataFrame(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = \"../input/wids2022/train.csv\"\n",
    "# test_path = \"../input/wids2022/test.csv\"\n",
    "train_path = \"data/train.csv\"\n",
    "test_path = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataprep(Dataset):\n",
    "\n",
    "    def __init__(self, train_path, test_path, size=0.1, is_train=True):\n",
    "        df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        TARGET_COLUMN = \"site_eui\"\n",
    "\n",
    "        self.is_train = is_train\n",
    "\n",
    "        train_df, val_df = train_test_split(\n",
    "            df,\n",
    "            test_size=0.1,\n",
    "            random_state=123\n",
    "        )\n",
    "\n",
    "        self.X_train, self.y_train = train_df.drop(columns=[TARGET_COLUMN]), train_df[TARGET_COLUMN]\n",
    "        self.X_val, self.y_val = val_df.drop(columns=[TARGET_COLUMN]), val_df[TARGET_COLUMN]\n",
    "        self.X_test = test_df\n",
    "\n",
    "    def imputation(self):\n",
    "        for X in (self.X_train, self.X_val, self.X_test):\n",
    "            max_year = X[\"year_built\"].max()\n",
    "            min_wind_speed = X[\"direction_max_wind_speed\"].min()\n",
    "            min_peak_wind_speed = X[\"direction_peak_wind_speed\"].min()\n",
    "            X[\"year_built\"] = X[\"year_built\"].replace(np.nan, max_year)\n",
    "            X[\"max_wind_speed\"] = X[\"max_wind_speed\"].replace(np.nan, 0)\n",
    "            X[\"days_with_fog\"] = X[\"days_with_fog\"].replace(np.nan, 0)\n",
    "            X[\"direction_max_wind_speed\"] = X[\"direction_max_wind_speed\"].replace(np.nan, min_wind_speed)\n",
    "            X[\"direction_peak_wind_speed\"] = X[\"direction_peak_wind_speed\"].replace(np.nan, min_peak_wind_speed)\n",
    "            X[\"energy_star_rating\"] = X[\"energy_star_rating\"].replace(np.nan, X[\"energy_star_rating\"].mean())\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    def engineer_features(self):\n",
    "        # Find Standard Deviation of min, max and avg temp among months\n",
    "        min_temps = [\n",
    "            \"january_min_temp\",\n",
    "            \"february_min_temp\",\n",
    "            \"march_min_temp\",\n",
    "            \"april_min_temp\",\n",
    "            \"may_min_temp\",\n",
    "            \"june_min_temp\",\n",
    "            \"july_min_temp\",\n",
    "            \"august_min_temp\",\n",
    "            \"september_min_temp\",\n",
    "            \"october_min_temp\",\n",
    "            \"november_min_temp\",\n",
    "            \"december_min_temp\"\n",
    "        ]\n",
    "\n",
    "        max_temps = [\n",
    "            \"january_max_temp\",\n",
    "            \"february_max_temp\",\n",
    "            \"march_max_temp\",\n",
    "            \"april_max_temp\",\n",
    "            \"may_max_temp\",\n",
    "            \"june_max_temp\",\n",
    "            \"july_max_temp\",\n",
    "            \"august_max_temp\",\n",
    "            \"september_max_temp\",\n",
    "            \"october_max_temp\",\n",
    "            \"november_max_temp\",\n",
    "            \"december_max_temp\"\n",
    "        ]\n",
    "\n",
    "        avg_temps = [\n",
    "            \"january_avg_temp\",\n",
    "            \"february_avg_temp\",\n",
    "            \"march_avg_temp\",\n",
    "            \"april_avg_temp\",\n",
    "            \"may_avg_temp\",\n",
    "            \"june_avg_temp\",\n",
    "            \"july_avg_temp\",\n",
    "            \"august_avg_temp\",\n",
    "            \"september_avg_temp\",\n",
    "            \"october_avg_temp\",\n",
    "            \"november_avg_temp\",\n",
    "            \"december_avg_temp\",\n",
    "        ]\n",
    "\n",
    "        self.numeric_features = [\n",
    "            \"floor_area\",\n",
    "            \"year_built\",\n",
    "            \"energy_star_rating\",\n",
    "            \"ELEVATION\",\n",
    "            \"cooling_degree_days\",\n",
    "            \"heating_degree_days\",\n",
    "            \"precipitation_inches\",\n",
    "            \"snowfall_inches\",\n",
    "            \"snowdepth_inches\",\n",
    "            \"avg_temp\",\n",
    "            \"days_below_30F\",\n",
    "            \"days_below_20F\",\n",
    "            \"days_below_10F\",\n",
    "            \"days_below_0F\",\n",
    "            \"days_above_80F\",\n",
    "            \"days_above_90F\",\n",
    "            \"days_above_100F\",\n",
    "            \"days_above_110F\",\n",
    "            \"max_wind_speed\",\n",
    "            \"days_with_fog\",\n",
    "            \"building_age\",\n",
    "            \"min_temp_std\",\n",
    "            \"max_temp_std\",\n",
    "            \"avg_temp_std\",\n",
    "            \"0-10\",\n",
    "            \"10-20\",\n",
    "            \"20-30\",\n",
    "            \"30-80\",\n",
    "            \"80-90\",\n",
    "            \"90-100\",\n",
    "            \"100-110\"\n",
    "        ] + min_temps + max_temps + avg_temps\n",
    "\n",
    "        self.categorical_features = [\n",
    "            \"Year_Factor\",\n",
    "            \"State_Factor\",\n",
    "            \"building_class\",\n",
    "            \"facility_type\",\n",
    "            \"direction_max_wind_speed\",\n",
    "            \"direction_peak_wind_speed\"\n",
    "        ]\n",
    "\n",
    "        self.drop_columns = [\n",
    "            \"id\"\n",
    "        ]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"building_age\"] = 2022 - X[\"year_built\"]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"min_temp_std\"] = X[min_temps].T.std()\n",
    "            X[\"max_temp_std\"] = X[max_temps].T.std()\n",
    "            X[\"avg_temp_std\"] = X[avg_temps].T.std()\n",
    "\n",
    "        days_above_below = [\n",
    "            \"days_below_30F\",\n",
    "            \"days_below_20F\",\n",
    "            \"days_below_10F\",\n",
    "            \"days_below_0F\",\n",
    "            \"days_above_80F\",\n",
    "            \"days_above_90F\",\n",
    "            \"days_above_100F\",\n",
    "            \"days_above_110F\",\n",
    "        ]\n",
    "\n",
    "        for X in [self.X_train, self.X_val, self.X_test]:\n",
    "            X[\"0-10\"] = X[\"days_below_10F\"] - X[\"days_below_0F\"]\n",
    "            X[\"10-20\"] = X[\"days_below_20F\"] - X[\"days_below_10F\"]\n",
    "            X[\"20-30\"] = X[\"days_below_30F\"] - X[\"days_below_20F\"]\n",
    "            X[\"80-90\"] = X[\"days_above_80F\"] - X[\"days_above_90F\"]\n",
    "            X[\"90-100\"] = X[\"days_above_90F\"] - X[\"days_above_100F\"]\n",
    "            X[\"100-110\"] = X[\"days_above_100F\"] - X[\"days_above_110F\"]\n",
    "            X[\"30-80\"] = (366 - X[days_above_below].sum(axis=1)).clip(lower=0)\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess(self):\n",
    "        pipe_numeric_feats = make_pipeline(\n",
    "           StandardScaler()\n",
    "        )\n",
    "        pipe_cat_feats = make_pipeline(\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse=False, drop='if_binary')\n",
    "        )\n",
    "        self.column_transformer = make_column_transformer(\n",
    "            (pipe_numeric_feats, self.numeric_features),\n",
    "            (pipe_cat_feats, self.categorical_features)\n",
    "        )\n",
    "\n",
    "        self.X_train_raw = self.X_train\n",
    "        self.X_val_raw = self.X_val\n",
    "        self.X_test_raw = self.X_test\n",
    "        self.X_train = self.column_transformer.fit_transform(self.X_train)\n",
    "        self.X_val = self.column_transformer.transform(self.X_val)\n",
    "        self.X_test = self.column_transformer.transform(self.X_test)\n",
    "\n",
    "        self.X_train_tensor = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        self.y_train_tensor = torch.tensor(self.y_train.values, dtype=torch.float32)\n",
    "        self.X_val_tensor = torch.tensor(self.X_val, dtype=torch.float32)\n",
    "        self.y_val_tensor = torch.tensor(self.y_val.values, dtype=torch.float32)\n",
    "        self.X_test_tensor = torch.tensor(self.X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valliakella/opt/anaconda3/envs/climatechange/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:170: UserWarning: Found unknown categories in columns [0, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_set = Dataprep(train_path, test_path)\n",
    "feature_set.imputation()\n",
    "feature_set.engineer_features()\n",
    "feature_set.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year_Factor                  0\n",
       "State_Factor                 0\n",
       "building_class               0\n",
       "facility_type                0\n",
       "floor_area                   0\n",
       "year_built                   0\n",
       "energy_star_rating           0\n",
       "ELEVATION                    0\n",
       "january_min_temp             0\n",
       "january_avg_temp             0\n",
       "january_max_temp             0\n",
       "february_min_temp            0\n",
       "february_avg_temp            0\n",
       "february_max_temp            0\n",
       "march_min_temp               0\n",
       "march_avg_temp               0\n",
       "march_max_temp               0\n",
       "april_min_temp               0\n",
       "april_avg_temp               0\n",
       "april_max_temp               0\n",
       "may_min_temp                 0\n",
       "may_avg_temp                 0\n",
       "may_max_temp                 0\n",
       "june_min_temp                0\n",
       "june_avg_temp                0\n",
       "june_max_temp                0\n",
       "july_min_temp                0\n",
       "july_avg_temp                0\n",
       "july_max_temp                0\n",
       "august_min_temp              0\n",
       "august_avg_temp              0\n",
       "august_max_temp              0\n",
       "september_min_temp           0\n",
       "september_avg_temp           0\n",
       "september_max_temp           0\n",
       "october_min_temp             0\n",
       "october_avg_temp             0\n",
       "october_max_temp             0\n",
       "november_min_temp            0\n",
       "november_avg_temp            0\n",
       "november_max_temp            0\n",
       "december_min_temp            0\n",
       "december_avg_temp            0\n",
       "december_max_temp            0\n",
       "cooling_degree_days          0\n",
       "heating_degree_days          0\n",
       "precipitation_inches         0\n",
       "snowfall_inches              0\n",
       "snowdepth_inches             0\n",
       "avg_temp                     0\n",
       "days_below_30F               0\n",
       "days_below_20F               0\n",
       "days_below_10F               0\n",
       "days_below_0F                0\n",
       "days_above_80F               0\n",
       "days_above_90F               0\n",
       "days_above_100F              0\n",
       "days_above_110F              0\n",
       "direction_max_wind_speed     0\n",
       "direction_peak_wind_speed    0\n",
       "max_wind_speed               0\n",
       "days_with_fog                0\n",
       "id                           0\n",
       "building_age                 0\n",
       "min_temp_std                 0\n",
       "max_temp_std                 0\n",
       "avg_temp_std                 0\n",
       "0-10                         0\n",
       "10-20                        0\n",
       "20-30                        0\n",
       "80-90                        0\n",
       "90-100                       0\n",
       "100-110                      0\n",
       "30-80                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set.X_train_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Temp zone #################################################\n",
    "\n",
    "# Apply imputation in all columns\n",
    "\n",
    "# Tried: X_train[\"facility_type\"].value_counts() -> Categorize in 3-4 categories\n",
    "# energy level / floor area group by mean and variance\n",
    "\n",
    "# Time series seasonal component in the monthly data -> Try feeding to RNNs\n",
    "# Take three month windows to calculate average -> Repeat it to narrow 12 features down to 1 or try SVD\n",
    "\n",
    "# use site_eui to order facility_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse(predictions, targets):\n",
    "    return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "\n",
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "def r2score_torch(predictions, target):\n",
    "    target_mean = torch.mean(target)\n",
    "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - predictions) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "\n",
    "def mse_torch(predictions, targets):\n",
    "    return torch.mean((predictions - targets) ** 2)\n",
    "\n",
    "\n",
    "def rmse_torch(predictions, targets):\n",
    "    return torch.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68181, 159)\n",
      "(7576, 159)\n",
      "(68181,)\n",
      "(7576,)\n"
     ]
    }
   ],
   "source": [
    "for dt in [\n",
    "    feature_set.X_train,\n",
    "    feature_set.X_val,\n",
    "    feature_set.y_train,\n",
    "    feature_set.y_val\n",
    "]:\n",
    "    print(dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_val_scores(model, X_train, y_train, X_val, y_val, return_train_score=False):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    score_dict = {\n",
    "        \"r2_val\": model.score(X_val, y_val),\n",
    "        \"mse_val\": mse(y_val, y_val_pred),\n",
    "        \"rmse_val\": rmse(y_val, y_val_pred),\n",
    "        \"mape_val\": mape(y_val, y_val_pred)\n",
    "    }\n",
    "\n",
    "    if return_train_score:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        score_dict[\"r2_train\"] = model.score(X_train, y_train)\n",
    "        score_dict[\"mse_train\"] = mse(y_train, y_train_pred)\n",
    "        score_dict[\"rmse_train\"] = rmse(y_train, y_train_pred)\n",
    "        score_dict[\"mape_train\"] = mape(y_train, y_train_pred)\n",
    "\n",
    "    scores_result = pd.Series(score_dict)\n",
    "\n",
    "    return model, scores_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(feature_set.column_transformer, Ridge(max_iter=10000))\n",
    "pipe_lasso = make_pipeline(feature_set.column_transformer, Lasso())\n",
    "pipe_rf = make_pipeline(feature_set.column_transformer, RandomForestRegressor())\n",
    "pipe_xgb = make_pipeline(feature_set.column_transformer, XGBRegressor(verbosity=0))#, eta=0.01, max_depth=7, n_estimators=1000))\n",
    "pipe_lgbm = make_pipeline(feature_set.column_transformer, LGBMRegressor())\n",
    "pipe_catboost = make_pipeline(feature_set.column_transformer, CatBoostRegressor(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def train(models, results):\n",
    "    for name, model in models.items():\n",
    "        print(f\"Start {name}!\")\n",
    "        start_time = time.time()\n",
    "        _, results[name] = cross_val_scores(\n",
    "            model,\n",
    "            feature_set.X_train_raw,\n",
    "            feature_set.y_train,\n",
    "            feature_set.X_val_raw,\n",
    "            feature_set.y_val,\n",
    "            return_train_score=True\n",
    "        )\n",
    "\n",
    "        print(f\"Done {name} in {round(time.time() - start_time)} secs!\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape\": mape_scorer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": pipe_ridge,\n",
    "    \"Lasso\": pipe_lasso,\n",
    "    \"Random Forest\": pipe_rf,\n",
    "    \"XGB\": pipe_xgb,\n",
    "    \"LGBM\": pipe_lgbm,\n",
    "    \"Cat Boost\": pipe_catboost,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Ridge!\n",
      "Done Ridge in 1 secs!\n",
      "Start Lasso!\n",
      "Done Lasso in 1 secs!\n",
      "Start Random Forest!\n",
      "Done Random Forest in 129 secs!\n",
      "Start XGB!\n",
      "Done XGB in 10 secs!\n",
      "Start LGBM!\n",
      "Done LGBM in 1 secs!\n",
      "Start Cat Boost!\n",
      "Done Cat Boost in 15 secs!\n"
     ]
    }
   ],
   "source": [
    "results = train(models, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>Cat Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.384524</td>\n",
       "      <td>0.211386</td>\n",
       "      <td>0.541005</td>\n",
       "      <td>0.533458</td>\n",
       "      <td>0.487960</td>\n",
       "      <td>0.529891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_val</th>\n",
       "      <td>1910.949846</td>\n",
       "      <td>2448.517626</td>\n",
       "      <td>1425.103499</td>\n",
       "      <td>1448.536019</td>\n",
       "      <td>1589.800862</td>\n",
       "      <td>1459.611494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_val</th>\n",
       "      <td>43.714412</td>\n",
       "      <td>49.482498</td>\n",
       "      <td>37.750543</td>\n",
       "      <td>38.059638</td>\n",
       "      <td>39.872307</td>\n",
       "      <td>38.204862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_val</th>\n",
       "      <td>52.049063</td>\n",
       "      <td>64.820178</td>\n",
       "      <td>38.562062</td>\n",
       "      <td>41.270712</td>\n",
       "      <td>44.991647</td>\n",
       "      <td>42.084243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.356380</td>\n",
       "      <td>0.175080</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>0.676095</td>\n",
       "      <td>0.538294</td>\n",
       "      <td>0.635198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_train</th>\n",
       "      <td>2204.851361</td>\n",
       "      <td>2825.931219</td>\n",
       "      <td>215.939300</td>\n",
       "      <td>1109.602617</td>\n",
       "      <td>1581.667625</td>\n",
       "      <td>1249.704719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>46.955845</td>\n",
       "      <td>53.159489</td>\n",
       "      <td>14.694873</td>\n",
       "      <td>33.310698</td>\n",
       "      <td>39.770185</td>\n",
       "      <td>35.351163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_train</th>\n",
       "      <td>59.282689</td>\n",
       "      <td>71.852982</td>\n",
       "      <td>15.783766</td>\n",
       "      <td>43.860027</td>\n",
       "      <td>49.522508</td>\n",
       "      <td>45.785898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ridge        Lasso  Random Forest          XGB         LGBM  \\\n",
       "r2_val         0.384524     0.211386       0.541005     0.533458     0.487960   \n",
       "mse_val     1910.949846  2448.517626    1425.103499  1448.536019  1589.800862   \n",
       "rmse_val      43.714412    49.482498      37.750543    38.059638    39.872307   \n",
       "mape_val      52.049063    64.820178      38.562062    41.270712    44.991647   \n",
       "r2_train       0.356380     0.175080       0.936965     0.676095     0.538294   \n",
       "mse_train   2204.851361  2825.931219     215.939300  1109.602617  1581.667625   \n",
       "rmse_train    46.955845    53.159489      14.694873    33.310698    39.770185   \n",
       "mape_train    59.282689    71.852982      15.783766    43.860027    49.522508   \n",
       "\n",
       "              Cat Boost  \n",
       "r2_val         0.529891  \n",
       "mse_val     1459.611494  \n",
       "rmse_val      38.204862  \n",
       "mape_val      42.084243  \n",
       "r2_train       0.635198  \n",
       "mse_train   1249.704719  \n",
       "rmse_train    35.351163  \n",
       "mape_train    45.785898  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68181, 159)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(Ridge(), min_features_to_select=120, n_jobs=-1)\n",
    "\n",
    "pipe_xgb_rfecv = make_pipeline(\n",
    "    feature_set.column_transformer, rfecv, XGBRegressor(verbosity=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feats = PolynomialFeatures(degree=2)\n",
    "\n",
    "pipe_poly_ridge = make_pipeline(\n",
    "    feature_set.column_transformer, rfecv, poly_feats, Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rfe_poly_ridge = {\n",
    "    \"XGB rfecv\": pipe_xgb_rfecv,\n",
    "    # \"Poly Ridge\": pipe_poly_ridge\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start XGB rfecv!\n",
      "Done XGB rfecv in 21 secs!\n"
     ]
    }
   ],
   "source": [
    "results = train(models_rfe_poly_ridge, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>Cat Boost</th>\n",
       "      <th>XGB rfecv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.384524</td>\n",
       "      <td>0.211386</td>\n",
       "      <td>0.541005</td>\n",
       "      <td>0.533458</td>\n",
       "      <td>0.487960</td>\n",
       "      <td>0.529891</td>\n",
       "      <td>0.514115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_val</th>\n",
       "      <td>1910.949846</td>\n",
       "      <td>2448.517626</td>\n",
       "      <td>1425.103499</td>\n",
       "      <td>1448.536019</td>\n",
       "      <td>1589.800862</td>\n",
       "      <td>1459.611494</td>\n",
       "      <td>1508.593032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_val</th>\n",
       "      <td>43.714412</td>\n",
       "      <td>49.482498</td>\n",
       "      <td>37.750543</td>\n",
       "      <td>38.059638</td>\n",
       "      <td>39.872307</td>\n",
       "      <td>38.204862</td>\n",
       "      <td>38.840611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_val</th>\n",
       "      <td>52.049063</td>\n",
       "      <td>64.820178</td>\n",
       "      <td>38.562062</td>\n",
       "      <td>41.270712</td>\n",
       "      <td>44.991647</td>\n",
       "      <td>42.084243</td>\n",
       "      <td>43.503444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.356380</td>\n",
       "      <td>0.175080</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>0.676095</td>\n",
       "      <td>0.538294</td>\n",
       "      <td>0.635198</td>\n",
       "      <td>0.631822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_train</th>\n",
       "      <td>2204.851361</td>\n",
       "      <td>2825.931219</td>\n",
       "      <td>215.939300</td>\n",
       "      <td>1109.602617</td>\n",
       "      <td>1581.667625</td>\n",
       "      <td>1249.704719</td>\n",
       "      <td>1261.267406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>46.955845</td>\n",
       "      <td>53.159489</td>\n",
       "      <td>14.694873</td>\n",
       "      <td>33.310698</td>\n",
       "      <td>39.770185</td>\n",
       "      <td>35.351163</td>\n",
       "      <td>35.514327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_train</th>\n",
       "      <td>59.282689</td>\n",
       "      <td>71.852982</td>\n",
       "      <td>15.783766</td>\n",
       "      <td>43.860027</td>\n",
       "      <td>49.522508</td>\n",
       "      <td>45.785898</td>\n",
       "      <td>46.249944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ridge        Lasso  Random Forest          XGB         LGBM  \\\n",
       "r2_val         0.384524     0.211386       0.541005     0.533458     0.487960   \n",
       "mse_val     1910.949846  2448.517626    1425.103499  1448.536019  1589.800862   \n",
       "rmse_val      43.714412    49.482498      37.750543    38.059638    39.872307   \n",
       "mape_val      52.049063    64.820178      38.562062    41.270712    44.991647   \n",
       "r2_train       0.356380     0.175080       0.936965     0.676095     0.538294   \n",
       "mse_train   2204.851361  2825.931219     215.939300  1109.602617  1581.667625   \n",
       "rmse_train    46.955845    53.159489      14.694873    33.310698    39.770185   \n",
       "mape_train    59.282689    71.852982      15.783766    43.860027    49.522508   \n",
       "\n",
       "              Cat Boost    XGB rfecv  \n",
       "r2_val         0.529891     0.514115  \n",
       "mse_val     1459.611494  1508.593032  \n",
       "rmse_val      38.204862    38.840611  \n",
       "mape_val      42.084243    43.503444  \n",
       "r2_train       0.635198     0.631822  \n",
       "mse_train   1249.704719  1261.267406  \n",
       "rmse_train    35.351163    35.514327  \n",
       "mape_train    45.785898    46.249944  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam Tune Random Forest \n",
    "\n",
    "params_rf = {\n",
    "    'randomforestregressor__n_estimators': [10, 100, 1000, 2000],\n",
    "    'randomforestregressor__max_depth': [5, 10, 25, 50],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt'],\n",
    "    'randomforestregressor__min_samples_split': [2, 3, 5],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestregressor__bootstrap':[True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf = RandomizedSearchCV(\n",
    "    pipe_rf,\n",
    "    params_rf,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metrics,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf.fit(feature_set.X_train_raw, feature_set.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(random_search_rf.cv_results_)\n",
    "# pd.DataFrame(random_search.cv_results_)[[\n",
    "#         \"mean_fit_time\",\n",
    "#         \"mean_score_time\",\n",
    "#         \"param_ridge__alpha\",\n",
    "#         \"mean_train_neg RMSE\",\n",
    "#         \"std_train_neg RMSE\",\n",
    "#         \"mean_test_mape\",\n",
    "#         \"mean_train_mape\",\n",
    "#         \"mean_test_r2\",\n",
    "#         \"mean_train_r2\"\n",
    "#     ]\n",
    "# ].sort_values(by='mean_test_r2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam Tune LGBMRegressor\n",
    "params_lgbm = {\n",
    "    'lgbmregressor__boosting_type': [\"rf\", \"gbdt\", \"dart\", \"goss\"]\n",
    "    'lgbmregressor__n_estimators': [10, 300, 1000],\n",
    "    'lgbmregressor__max_depth': [5, 10, 15],\n",
    "    'lgbmregressor_num_leaves': [10, 20, 40],\n",
    "    'lgbmregressor__learning_rate': [0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    pipe_lgbm,\n",
    "    params_lgbm,\n",
    "    n_jobs=-1,\n",
    "    n_iter=20,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metrics,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(random_search_lgbm.cv_results_)\n",
    "pd.DataFrame(random_search_lgbm.cv_results_)[[\n",
    "        \"mean_fit_time\",\n",
    "        \"mean_score_time\",\n",
    "        \"params\",\n",
    "        \"mean_train_neg RMSE\",\n",
    "        \"mean_test_neg RMSE\",\n",
    "        \"mean_test_mape\",\n",
    "        \"mean_train_mape\",\n",
    "        \"mean_test_r2\",\n",
    "        \"mean_train_r2\"\n",
    "    ]\n",
    "].sort_values(by=\"mean_test_r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_lgbm.best_params_)\n",
    "print(random_search_lgbm.best_score_)\n",
    "# {'lgbmregressor__n_estimators': 1000, 'lgbmregressor__max_depth': 20}\n",
    "# 0.49699611783887543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperparamTune XGBoost\n",
    "params_xgb = {\n",
    "    'xgbregressor__n_estimators': [10, 100, 1000],\n",
    "    'xgbregressor__max_depth': [3, 5, 7, 12],\n",
    "    'xgbregressor__eta': [0.01, 0.03, 0.01, 0.3],\n",
    "    'xgbregressor__subsample': [0.5, 0.8, 1],\n",
    "    'xgbregressor__colsample_bytree': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_xgb = RandomizedSearchCV(\n",
    "    pipe_xgb,\n",
    "    params_xgb,\n",
    "    n_jobs=-1,\n",
    "    n_iter=20,\n",
    "    return_train_score=True,\n",
    "    scoring=scoring_metrics,\n",
    "    refit=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_xgb.fit(feature_set.X_train_raw, feature_set.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(random_search_xgb.cv_results_)\n",
    "pd.DataFrame(random_search_xgb.cv_results_)[[\n",
    "        \"mean_fit_time\",\n",
    "        \"mean_score_time\",\n",
    "        \"params\",\n",
    "        \"mean_train_neg RMSE\",\n",
    "        \"mean_test_neg RMSE\",\n",
    "        \"mean_test_mape\",\n",
    "        \"mean_train_mape\",\n",
    "        \"mean_test_r2\",\n",
    "        \"mean_train_r2\"\n",
    "    ]\n",
    "].sort_values(by=\"mean_test_r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_xgb.best_params_)\n",
    "print(random_search_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_selected = {\n",
    "    \"Ridge\": pipe_ridge,\n",
    "    \"XGB\": pipe_xgb,\n",
    "    \"LGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost\n",
    "#     \"<>_rfecv\": pipe_<>_rfecv,\n",
    "#     \"Poly Ridge\": pipe_poly_ridge,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(list(models_selected.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Stacking!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valliakella/opt/anaconda3/envs/climatechange/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:170: UserWarning: Found unknown categories in columns [4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/valliakella/opt/anaconda3/envs/climatechange/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:170: UserWarning: Found unknown categories in columns [4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/valliakella/opt/anaconda3/envs/climatechange/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:170: UserWarning: Found unknown categories in columns [4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/valliakella/opt/anaconda3/envs/climatechange/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:170: UserWarning: Found unknown categories in columns [4] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Stacking in 122 secs!\n"
     ]
    }
   ],
   "source": [
    "name = \"Stacking\"\n",
    "\n",
    "print(f\"Start {name}!\")\n",
    "start_time = time.time()\n",
    "\n",
    "_, results[name] = cross_val_scores(\n",
    "    stacking_model,\n",
    "    feature_set.X_train_raw,\n",
    "    feature_set.y_train,\n",
    "    feature_set.X_val_raw,\n",
    "    feature_set.y_val,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Done {name} in {round(time.time() - start_time)} secs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Voting!\n",
      "Done Voting in 27 secs!\n"
     ]
    }
   ],
   "source": [
    "averaging_model = VotingRegressor(list(models_selected.items()))\n",
    "name = \"Voting\"\n",
    "\n",
    "print(f\"Start {name}!\")\n",
    "start_time = time.time()\n",
    "\n",
    "_, results[name] = cross_val_scores(\n",
    "    averaging_model,\n",
    "    feature_set.X_train_raw,\n",
    "    feature_set.y_train,\n",
    "    feature_set.X_val_raw,\n",
    "    feature_set.y_val,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(f\"Done {name} in {round(time.time() - start_time)} secs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>Cat Boost</th>\n",
       "      <th>XGB rfecv</th>\n",
       "      <th>Stacking</th>\n",
       "      <th>Voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.384524</td>\n",
       "      <td>0.211386</td>\n",
       "      <td>0.541005</td>\n",
       "      <td>0.533458</td>\n",
       "      <td>0.487960</td>\n",
       "      <td>0.529891</td>\n",
       "      <td>0.514115</td>\n",
       "      <td>0.541165</td>\n",
       "      <td>0.514609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_val</th>\n",
       "      <td>1910.949846</td>\n",
       "      <td>2448.517626</td>\n",
       "      <td>1425.103499</td>\n",
       "      <td>1448.536019</td>\n",
       "      <td>1589.800862</td>\n",
       "      <td>1459.611494</td>\n",
       "      <td>1508.593032</td>\n",
       "      <td>1424.607779</td>\n",
       "      <td>1507.057752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_val</th>\n",
       "      <td>43.714412</td>\n",
       "      <td>49.482498</td>\n",
       "      <td>37.750543</td>\n",
       "      <td>38.059638</td>\n",
       "      <td>39.872307</td>\n",
       "      <td>38.204862</td>\n",
       "      <td>38.840611</td>\n",
       "      <td>37.743977</td>\n",
       "      <td>38.820842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_val</th>\n",
       "      <td>52.049063</td>\n",
       "      <td>64.820178</td>\n",
       "      <td>38.562062</td>\n",
       "      <td>41.270712</td>\n",
       "      <td>44.991647</td>\n",
       "      <td>42.084243</td>\n",
       "      <td>43.503444</td>\n",
       "      <td>40.732479</td>\n",
       "      <td>43.849638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.356380</td>\n",
       "      <td>0.175080</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>0.676095</td>\n",
       "      <td>0.538294</td>\n",
       "      <td>0.635198</td>\n",
       "      <td>0.631822</td>\n",
       "      <td>0.672462</td>\n",
       "      <td>0.591475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse_train</th>\n",
       "      <td>2204.851361</td>\n",
       "      <td>2825.931219</td>\n",
       "      <td>215.939300</td>\n",
       "      <td>1109.602617</td>\n",
       "      <td>1581.667625</td>\n",
       "      <td>1249.704719</td>\n",
       "      <td>1261.267406</td>\n",
       "      <td>1122.047889</td>\n",
       "      <td>1399.486235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>46.955845</td>\n",
       "      <td>53.159489</td>\n",
       "      <td>14.694873</td>\n",
       "      <td>33.310698</td>\n",
       "      <td>39.770185</td>\n",
       "      <td>35.351163</td>\n",
       "      <td>35.514327</td>\n",
       "      <td>33.496983</td>\n",
       "      <td>37.409708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape_train</th>\n",
       "      <td>59.282689</td>\n",
       "      <td>71.852982</td>\n",
       "      <td>15.783766</td>\n",
       "      <td>43.860027</td>\n",
       "      <td>49.522508</td>\n",
       "      <td>45.785898</td>\n",
       "      <td>46.249944</td>\n",
       "      <td>43.564034</td>\n",
       "      <td>48.421140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Ridge        Lasso  Random Forest          XGB         LGBM  \\\n",
       "r2_val         0.384524     0.211386       0.541005     0.533458     0.487960   \n",
       "mse_val     1910.949846  2448.517626    1425.103499  1448.536019  1589.800862   \n",
       "rmse_val      43.714412    49.482498      37.750543    38.059638    39.872307   \n",
       "mape_val      52.049063    64.820178      38.562062    41.270712    44.991647   \n",
       "r2_train       0.356380     0.175080       0.936965     0.676095     0.538294   \n",
       "mse_train   2204.851361  2825.931219     215.939300  1109.602617  1581.667625   \n",
       "rmse_train    46.955845    53.159489      14.694873    33.310698    39.770185   \n",
       "mape_train    59.282689    71.852982      15.783766    43.860027    49.522508   \n",
       "\n",
       "              Cat Boost    XGB rfecv     Stacking       Voting  \n",
       "r2_val         0.529891     0.514115     0.541165     0.514609  \n",
       "mse_val     1459.611494  1508.593032  1424.607779  1507.057752  \n",
       "rmse_val      38.204862    38.840611    37.743977    38.820842  \n",
       "mape_val      42.084243    43.503444    40.732479    43.849638  \n",
       "r2_train       0.635198     0.631822     0.672462     0.591475  \n",
       "mse_train   1249.704719  1261.267406  1122.047889  1399.486235  \n",
       "rmse_train    35.351163    35.514327    33.496983    37.409708  \n",
       "mape_train    45.785898    46.249944    43.564034    48.421140  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_block(input_size, output_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, output_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2)\n",
    "    )\n",
    "\n",
    "class Extractlastcell(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out, _ = x\n",
    "        return out[-1]\n",
    "\n",
    "\n",
    "class EnergyRegressor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EnergyRegressor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=2 * input_size, num_layers=2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.layers = nn.Sequential(\n",
    "            linear_block(2 * input_size, 3 * input_size),\n",
    "            linear_block(3 * input_size, 5 * input_size),\n",
    "            linear_block(5 * input_size, 10 * input_size),\n",
    "            linear_block(10 * input_size, 7 * input_size),\n",
    "            linear_block(7 * input_size, 5 * input_size),\n",
    "            linear_block(5 * input_size, 3 * input_size),\n",
    "            linear_block(3 * input_size, input_size),\n",
    "            nn.Linear(input_size, 1000),\n",
    "            nn.Linear(1000, 700),\n",
    "            nn.Linear(700, 400), \n",
    "            nn.Linear(400, 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.to(device)\n",
    "        # X (sequence length, batch size, input size)\n",
    "        X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "        X, _ = self.lstm(X)\n",
    "        X = X[-1]\n",
    "        X = self.tanh(X)\n",
    "        X = self.layers(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(TensorDataset(feature_set.X_train_tensor, feature_set.y_train_tensor), batch_size=32, shuffle=True)\n",
    "validloader = DataLoader(TensorDataset(feature_set.X_val_tensor, feature_set.y_val_tensor), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnergyRegressor(feature_set.X_train_tensor.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, criterion, optimizer, trainloader, validloader, epochs):\n",
    "    train_mse = 0\n",
    "    train_rmse = 0\n",
    "    train_r2 = 0\n",
    "    val_mse = 0\n",
    "    val_rmse = 0\n",
    "    val_r2 = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_batch_mse = []\n",
    "        train_batch_rmse = []\n",
    "        train_batch_r2 = []\n",
    "        val_batch_mse = []\n",
    "        val_batch_rmse = []\n",
    "        val_batch_r2 = []\n",
    "\n",
    "        model.train(True)\n",
    "\n",
    "        for X, y in trainloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X).flatten()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss = loss.to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            mse_train = mse_torch(y_hat, y)\n",
    "            rmse_train = rmse_torch(y_hat, y)\n",
    "            r2_train = r2score_torch(y_hat, y)\n",
    "            train_batch_mse.append(mse_train)\n",
    "            train_batch_rmse.append(rmse_train)\n",
    "            train_batch_r2.append(r2_train)\n",
    "        \n",
    "        train_mse = torch.sum(torch.Tensor(train_batch_mse)) / len(trainloader)\n",
    "        train_rmse = torch.sum(torch.Tensor(train_batch_rmse)) / len(trainloader)\n",
    "        train_r2 = torch.sum(torch.Tensor(train_batch_r2)) / len(trainloader)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_valid, y_valid in validloader:\n",
    "                X_valid = X_valid.to(device)\n",
    "                y_valid = y_valid.to(device).flatten()\n",
    "                y_hat_val = model(X_valid)\n",
    "                mse_val = mse_torch(y_hat_val, y_valid)\n",
    "                rmse_val = rmse_torch(y_hat_val, y_valid)\n",
    "                r2_val = r2score_torch(y_hat_val, y_valid)\n",
    "                val_batch_mse.append(mse_val)\n",
    "                val_batch_rmse.append(rmse_val)\n",
    "                val_batch_r2.append(r2_val)\n",
    "            val_mse = torch.sum(torch.Tensor(val_batch_mse)) / len(validloader)\n",
    "            val_rmse = torch.sum(torch.Tensor(val_batch_rmse)) / len(validloader)\n",
    "            val_r2 = torch.sum(torch.Tensor(val_batch_r2)) / len(validloader) \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}:\\tTrain:\\tMSE: {round(train_mse.item(), 4)}. RMSE: {round(train_rmse.item(), 4)}, R2: {round(train_r2.item(), 4)}.\")\n",
    "        print(f\"\\t\\tVal:\\tMSE: {round(val_mse.item(), 4)}, RMSE: {round(val_rmse.item(), 4)}, R2: {round(val_r2.item(), 4)}.\")\n",
    "        print(\"-\" * 80)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = criterion.to(device)\n",
    "trained_model = trainer(model, criterion, optimizer, trainloader, validloader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    return model(X.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(trained_model, feature_set.X_test_tensor)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"id\": feature_set.X_test_raw[\"id\"],\n",
    "               \"site_eui\": predictions.cpu().detach().numpy().flatten()}\n",
    "pd.DataFrame(results_dict).set_index(\"id\").to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         residential = [\n",
    "#             \"Multifamily_Uncategorized\",\n",
    "#             \"2to4_Unit_Building\",\n",
    "#             \"5plus_Unit_Building\",\n",
    "#             \"Religious_worship\",\n",
    "#             \"Parking_Garage\",\n",
    "#             \"Mixed_Use_Predominantly_Residential\"\n",
    "#         ]\n",
    "\n",
    "#         industrial = [\n",
    "#             \"Warehouse_Nonrefrigerated\",\n",
    "#             \"Warehouse_Distribution_or_Shipping_center\",\n",
    "#             \"Warehouse_Selfstorage\",\n",
    "#             \"Industrial\",\n",
    "#             \"Warehouse_Uncategorized\",\n",
    "#             \"Warehouse_Refrigerated\",\n",
    "#             \"Laboratory\",\n",
    "#             \"Data_Center\"\n",
    "#         ]\n",
    "\n",
    "#         commercial = list(\n",
    "#             set(self.X_train[\"facility_type\"].value_counts().index) -\n",
    "#             set(residential) - set(industrial)\n",
    "#         )\n",
    "\n",
    "#         temp = pd.concat([self.X_train[\"facility_type\"], feature_set.y_train], axis=1)\n",
    "#         convert_dic = dict(temp[[\"facility_type\", \"site_eui\"]].groupby(\"facility_type\")[\"site_eui\"].mean().sort_values())\n",
    "\n",
    "#         for X in [self.X_train, self.X_val, self.X_test]:\n",
    "#             for facility_type in [\n",
    "#                 \"Food\",\n",
    "#                 \"Education\",\n",
    "#                 \"Health_Care\",\n",
    "#                 \"Public_Assembly\",\n",
    "#                 \"Public_Safety\",\n",
    "#                 \"Lodging\",\n",
    "#                 \"Warehouse\",\n",
    "#                 \"Office\",\n",
    "#                 \"Service\",\n",
    "#                 \"Retail\"\n",
    "#             ]:\n",
    "#                 X[\"facility_type\"] = [\n",
    "#                     facility_type if f_type.lower().startswith(facility_type.lower())\n",
    "#                     else f_type\n",
    "#                     for f_type in X[\"facility_type\"]\n",
    "#                 ]\n",
    "# #             X.replace({\"facility_type\": convert_dic}, inplace=True)\n",
    "# #         #     X[\"facility_type\"] = [\n",
    "# #         #             \"commercial\" if f_type in commercial\n",
    "# #         #             else \"residential\" if f_type in residential\n",
    "# #         #             else \"industrial\"\n",
    "# #         #         for f_type in X[\"facility_type\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:climatechange]",
   "language": "python",
   "name": "conda-env-climatechange-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
